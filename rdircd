#!/usr/bin/env python3

import itertools as it, operator as op, functools as ft
import os, sys, io, stat, re, time, secrets, enum, json, zlib, math
import asyncio, socket, signal, inspect, traceback, contextlib as cl
import hashlib, base64, random, unicodedata, ast, urllib.parse
import configparser, tempfile, datetime as dt, pathlib as pl
import collections as cs, collections.abc as cs_abc
import logging, logging.handlers

import aiohttp



class RDIRCDConfigBase:
	# Note: string time intervals can be either simple floats or stuff like
	#  "30s", "10min", "1h 20m", "1mo3d5h", etc - see parse_duration func for that.

	version = '1.234' # git-version: py-str

	irc_host = '127.0.0.1'
	irc_port = 6667
	irc_password = ''
	irc_host_af = 0
	irc_auth_tbf = '30:8'
	irc_uid_len = 4 # can be increased to fix conflicts
	irc_uid_seed = ''
	irc_prefix_edit = '[edit] '
	irc_prefix_attachment = '[att] '
	irc_prefix_embed = '[em.{}] '
	irc_prefix_sticker = '[sticker] '
	irc_prefix_uis = '[UIs] '
	irc_prefix_guild_event = '--- ' # user bans, friend statuses, scheduled guild events, etc
	irc_names_timeout = '1d' # time since last activity
	irc_motd_file_path = '' # file path to read for motd command

	irc_len_hwm = 450 # will probably still work with most clients
	irc_len_lwm = 300
	irc_len_topic = 300 # cannot be split, so is truncated instead
	irc_len_monitor = 350 # to tuncate long lines in #rdircd.monitor
	irc_len_monitor_lines = 4 # to tuncate multiline msgs in #rdircd.monitor

	irc_chan_modes = False # causes needless spam on ZNC reconnects
	irc_chan_auto_join_re = '' # regexp to match against irc chan names to auto-join
	irc_disable_reactions = False # disables all "--- reacts" messages
	irc_inline_reply_quote_len = 90 # 0 = disable

	irc_private_chat_min_others_to_use_id_name = 2 # for #me.chat.user1+user2+... vs #me.chat.<id>
	irc_private_chat_name_len = 120 # long userlist-name will truncate usernames, depends on client
	irc_private_chat_name_user_min_len = 20 # don't truncate usernames in userlist-name beyond that

	irc_thread_chan_name_len = 30 # truncate thread-name to this len in thread-chans, 0 = just id

	discord_auto_connect = True
	discord_api_url = 'https://discord.com/api/v{api_ver}/'
	discord_api_user_agent = ( f'rdircd/{version}'
		f' (reliable-discord-irc-client) aiohttp/{aiohttp.__version__}' )
	discord_ws_timeout = 20.0
	discord_ws_heartbeat = 15.0
	discord_ws_reconnect_min = '65.0'
	discord_ws_reconnect_max = '700.0'
	discord_ws_reconnect_factor = 1.6
	discord_ws_reconnect_warn = '3600:3' # to filter-out expected reconnects
	discord_ws_reconnect_on_auth_fail = False # useful for discord service disruptions
	discord_http_delay_padding = 10.0 # added to retry_after
	discord_http_timeout_conn = 40.0
	discord_http_timeout_conn_sock = 30.0
	discord_user_mention_cache_timeout = 3 * 24 * 3600
	discord_gateway = ''

	# discord_msg_mention_re should match only discord user mentions.
	# "nick" group must be irc nick, to be replaced with
	#  discord user-id tag, all other capturing groups are replaced by "".
	# Don't use repeating/overlapping capturing groups (w/o "?:"). Empty value - disable.
	discord_msg_mention_re = r'(?:^|\s)(@)(?P<nick>[^\s,;@+]+)'
	# discord_msg_mention_re_ignore is matched
	#  against full capture of the regexp above, not full line.
	discord_msg_mention_re_ignore = r'@(?:everyone|here)'
	discord_msg_mention_irc_decode = True # try irc_name_revert on mention-matches from irc
	discord_msg_confirm_timeout = 25.0 # can include extra requests to resolve user-mentions

	# Prefix for thread-id values, used in thread-chan names
	#   and msg prefixes if propagation from these to parent channel is enabled.
	discord_thread_id_prefix = '='
	# discord_thread_msgs_in_parent_chan propagates messages from threads to a parent channel,
	#   adding thread-id prefix, through which response can be redirected as well, if enabled.
	discord_thread_msgs_in_parent_chan = True
	# Enable to see mirrored msgs
	#   in #rdircd.monitor channel(s) too - e.g. to have it all there as-is.
	discord_thread_msgs_in_parent_chan_monitor = False
	# discord_thread_msgs_in_parent_chan_full_prefix - enable to use full
	#  chan-name prefix instead of shorter thread-id, for IRC clients with easy click-to-join.
	discord_thread_msgs_in_parent_chan_full_prefix = False
	# discord_thread_redirect_prefixed_responses_from_parent_chan allows to send msgs
	#   to threads from parent channel by prepending thread-id prefix to each one of these.
	# For example "=vot5 hi!" will send "hi!" msg to =vot5 thread
	#   sub-channel only, or print an error if such thread-id is not recognized.
	discord_thread_redirect_prefixed_responses_from_parent_chan = True

	auth_email = ''
	auth_password = ''
	auth_token = ''
	auth_token_manual = False # never fetch/refresh auth token, for captcha/mfa logins

	debug_verbose = False
	debug_asyncio = False
	debug_msg_cut = 50
	debug_proto_cut = 90
	debug_proto_log_shared = True
	debug_proto_log_file = ''
	debug_proto_log_file_size = int(1.5e6)
	debug_proto_log_file_count = 9
	debug_proto_aiohttp = True
	debug_log_file = '' # not affected by "verbose" option in any way
	debug_log_file_size = int(1.5e6)
	debug_log_file_count = 9
	debug_chan_proto_tail = 50
	debug_chan_proto_cut = 230

	_conf_path = '~/.rdircd.ini'
	_conf_sections = 'irc', 'discord', 'auth', 'debug'
	_conf_sections_old = dict(auth_main='auth') # old -> new renames

	_conv_irc_chan_auto_join_re = lambda s, v: re.compile(v or '^$')
	_conv_discord_msg_mention_re_ignore = lambda s, v: v and re.compile(v)
	def _conv_discord_msg_mention_re(self, v):
		if not v: return
		rx = re.compile(v)
		if 'nick' not in rx.groupindex:
			raise ValueError(f'Missing "nick" group in discord-mentions regexp: {v!r}')
		return rx



err_fmt = lambda err: '[{}] {}'.format(err.__class__.__name__, err)

class LogMessage:
	def __init__(self, fmt, a, k): self.fmt, self.a, self.k = fmt, a, k
	def __str__(self): return self.fmt.format(*self.a, **self.k) if self.a or self.k else self.fmt

class LogStyleAdapter(logging.LoggerAdapter):
	def __init__(self, logger, extra=None): super().__init__(logger, extra or {})
	def log(self, level, msg, *args, **kws):
		if not self.isEnabledFor(level): return
		log_kws = dict((k, kws.pop(k, None)) for k in ['extra', 'exc_info'])
		if not isinstance(log_kws['extra'], dict): log_kws['extra'] = dict(extra=log_kws['extra'])
		msg, kws = self.process(msg, kws)
		self.logger._log(level, LogMessage(msg, args, kws), (), **log_kws)

class LogFuncHandler(logging.Handler):
	def __init__(self, func):
		super().__init__()
		self.func, self.locked = func, False
	def emit(self, record):
		if self.locked: return # to avoid logging-of-logging loops, assuming sync call
		self.locked = True
		try: self.func(self.format(record))
		# except Exception: self.handleError(record) # too noisy
		except Exception as err: log_bak.exception('LogFuncHandler failed - {}', err_fmt(err))
		finally: self.locked = False

class LogEmptyMsgFilter(logging.Filter):
	def filter(self, record):
		msg = record.msg
		return bool(msg if isinstance(msg, str) else msg.fmt)
log_empty_filter = LogEmptyMsgFilter()

class LogProtoDebugFilter(logging.Filter):
	debug_re = re.compile(rb'^:core (PRIVMSG|NOTICE) #rdircd\.debug :')
	def filter(self, record):
		try: st, msg = record.extra
		except: return True
		return not ( st == ' >>'
			and isinstance(msg, bytes)
			and self.debug_re.search(msg) )
log_proto_debug_filter = LogProtoDebugFilter()

class LogProtoFormatter(logging.Formatter):
	last_ts = last_rec = last_reltime = None
	def format(self, record):
		if id(record) != self.last_rec:
			reltime = (record.created - self.last_ts) if self.last_ts else 0
			self.last_reltime = '{}{:,.3f}'.format('+' if reltime >= 0 else '', reltime)
			self.last_ts, self.last_rec = record.created, id(record)
		record.reltime = self.last_reltime
		record.asctime = time.strftime(
			'%Y-%m-%dT%H:%M:%S', time.localtime(record.created) )
		record.asctime += f'.{record.msecs:03.0f}'
		if record.name.startswith('proto.'): record.name = record.name[6:]
		try:
			st, msg = record.extra
			if isinstance(msg, bytes): msg = json.dumps(msg.decode())
		except Exception as err:
			st, msg = 'err', err_fmt(err)
			log_bak.exception('LogProtoFormatter failed - {}', msg)
		record.message = f'{st} :: {msg}'
		return self.formatMessage(record)

class LogFileHandler(logging.handlers.RotatingFileHandler):
	def set_file(self, path):
		self.stream, self.baseFilename = None, os.path.abspath(os.fspath(path))
	def get_file(self): return self.baseFilename

class LogLevelCounter(logging.Handler):
	def __init__(self, *args, **kws):
		super().__init__(*args, **kws)
		self.counts = cs.Counter()
	def emit(self, record):
		self.counts['all'] += 1
		if record.levelno <= logging.DEBUG: return
		self.counts[record.levelname.lower()] += 1

get_logger = lambda name: LogStyleAdapter(logging.getLogger(name))
log_bak = get_logger('fallback')
log_proto_root = logging.getLogger('proto')


def setup_aiohttp_trace_logging(log):
	tc = aiohttp.TraceConfig()

	@cl.contextmanager
	def log_req(part, ident=None, t='req'):
		if not log.isEnabledFor(logging.DEBUG): return
		try:
			dt = ' >>' if t == 'req' else '<< '
			if ident: log.debug('', extra=(dt, f'{t} :: {ident}'))
			log.debug('', extra=(dt, f'{t} :: {part} start'))
			yield log
			log.debug('', extra=(dt, f'{t} :: {part} end'))
		except Exception as err:
			err = err_fmt(err)
			log.exception( 'Protocol logging failed: {}',
				err, extra=('xxx', f'{t} :: {part} FAIL :: {err}') )

	# This does not dump all req headers, but should be good enough
	async def on_req_start(s, tc_ctx, ps):
		tc_ctx.req_uid = str_hash(os.urandom(8))
		with log_req('headers', f'[{tc_ctx.req_uid}] {ps.method} {ps.url}') as log:
			for k, v in ps.headers.items(): log.debug('', extra=('  >', f'  {k}: {v}'))
	tc.on_request_start.append(on_req_start)

	async def on_req_chunk(s, tc_ctx, ps):
		a = getattr(tc_ctx, 'pos', 0)
		b = tc_ctx.pos = a + len(ps.chunk)
		with log_req('body', f'[{tc_ctx.req_uid}] {a}-{b}') as log:
			if ps.chunk: log.debug('', extra=('  >', ps.chunk))
	tc.on_request_chunk_sent.append(on_req_chunk)

	async def on_req_done(s, tc_ctx, ps):
		res_info = ( '{0.status} {0.reason}'
			' HTTP/{0.version.major}.{0.version.minor}' ).format(ps.response)
		with log_req('headers', f'[{tc_ctx.req_uid}] {res_info}', 'res') as log:
			for k, v in ps.response.headers.items(): log.debug('', extra=('<  ', f'  {k}: {v}'))
		with log_req('body', f'[{tc_ctx.req_uid}]', 'res') as log:
			log.debug('', extra=('<  ', await ps.response.read()))
	tc.on_request_end.append(on_req_done)

	return tc

def sockopt_resolve(prefix, v):
	prefix = prefix.upper()
	for k in dir(socket):
		if not k.startswith(prefix): continue
		if getattr(socket, k) == v: return k[len(prefix):]
	return v

# str_norm is NOT used in irc, where ascii-only casefold is more traditional
str_norm = lambda v: unicodedata.normalize('NFKC', v.strip()).casefold()

def str_part(s, sep, default=None):
	'Examples: str_part("user@host", "<@", "root"), str_part("host:port", ":>")'
	c = sep.strip('<>')
	if sep.strip(c) == '<': return (default, s) if c not in s else s.split(c, 1)
	else: return (s, default) if c not in s else s.rsplit(c, 1)

def str_repr(s, max_len=50, len_bytes=False, ext=' ...[{s_len}]'):
	'Truncates longer strings to "max_len", adding "ext" suffix.'
	if isinstance(s, bytes): s = s.decode('utf-8', 'replace')
	if not isinstance(s, str): s = str(s)
	s_len, s_repr, ext_tpl = f'{len(s):,d}', repr(s)[1:-1], ext.format(s_len='12/345')
	if max_len > 0 and len(s_repr) > max_len:
		s_len = f'{max_len}/{s_len}'
		if not len_bytes: s_repr = s_repr[:max_len - len(ext_tpl)] + ext.format(s_len=s_len)
		else:
			n = max_len - len(ext_tpl.encode())
			s_repr = s_repr.encode()[:n].decode(errors='ignore') + ext.format(s_len=s_len)
	return s_repr

irc_name_eq = lambda a, b: a.lower() == b.lower()


def str_hash(s, c=None, key='rdircd', strip=''):
	s_raw, s = s, base64.urlsafe_b64encode(
		hashlib.blake2s(str(s).encode(), key=key.encode()).digest() ).decode()
	for sc in strip + '-_=': s = s.replace(sc, '')
	if c is None: return s
	for n in range(30): # limit is to avoid unlikely a -> ... -> a loops
		if len(s) < c: s = str_hash(s, c, key, strip)
		if len(s) >= c: break
	else: raise RuntimeError(f'str_hash() failed on: {s_raw!r} {[c, key, strip]}')
	return s[:c]

def tuple_hash(t, c=None, key='rdircd'):
	s = '\0'.join(str(v).replace('\0', '\0\0') for v in t)
	return str_hash(s, c=c, key=key)


def data_repr(data):
	pp = getattr(data_repr, '_pp', None)
	if not pp:
		import pprint as pp
		pp = data_repr._pp = pp.PrettyPrinter(indent=2, width=100, compact=True)
	return pp.pformat(data)

def force_list(v):
	if not v: v = list()
	elif isinstance(v, cs_abc.ValuesView): v = list(v)
	elif not isinstance(v, list): v = [v]
	return v

def dict_update(d, du_iter=None, sync=True):
	keys_old, du = set(d.keys()), dict()
	if du_iter: du.update(du_iter)
	d.update(du)
	if sync: return dict((k, d.pop(k)) for k in keys_old.difference(du))

@cl.contextmanager
def safe_replacement(path, *open_args, mode=None, **open_kws):
	path = str(path)
	if mode is None:
		try: mode = stat.S_IMODE(os.lstat(path).st_mode)
		except OSError: pass
	open_kws.update( delete=False,
		dir=os.path.dirname(path), prefix=os.path.basename(path)+'.' )
	if not open_args: open_kws['mode'] = 'w'
	with tempfile.NamedTemporaryFile(*open_args, **open_kws) as tmp:
		try:
			if mode is not None: os.fchmod(tmp.fileno(), mode)
			yield tmp
			if not tmp.closed: tmp.flush()
			os.rename(tmp.name, path)
		finally:
			try: os.unlink(tmp.name)
			except OSError: pass

def file_tail(p, n, grep=None, bs=100 * 2**10):
	import mmap
	lines = list()
	with open(p,'rb') as src:
		a, buff, mm = 1, b'', mmap.mmap(
			src.fileno(), 0, access=mmap.ACCESS_READ )
		while len(lines) < n:
			b = a + bs
			a, buff, end = b, buff + mm[-a:-b:-1], b > len(mm)
			while True:
				try: line, buff = buff.split(b'\n', 1)
				except ValueError:
					if end and buff: line, buff = buff, b''
					else: break
				if line: lines.append(line[::-1].decode())
			if end: break
	return list(reversed(lines[:n]))

def token_bucket(spec, negative_tokens=False):
	'''Spec: { interval_seconds: float | float_a/float_b }[:burst_float]
			Examples: 1/4:5 (interval=0.25s, rate=4/s, burst=5), 5, 0.5:10, 20:30.
		Expects a number of tokens (can be float, default: 1)
			and *always* subtracts these.
		Yields either None if there's enough
			tokens or delay (in seconds, float) until when there will be.'''
	try:
		try: interval, burst = spec.rsplit(':', 1)
		except (ValueError, AttributeError): interval, burst = spec, 1.0
		else: burst = float(burst)
		if isinstance(interval, str):
			try: a, b = interval.split('/', 1)
			except ValueError: interval = float(interval)
			else: interval = float(a) / float(b)
		if min(interval, burst) < 0: raise ValueError()
	except: raise ValueError('Invalid format for rate-limit: {!r}'.format(spec))
	# log.debug('tbf parameters: interval={:.1f}, burst={:.1f}', interval, burst)
	tokens, rate, ts_sync = max(0, burst - 1), interval**-1, time.monotonic()
	val = (yield) or 1
	while True:
		ts = time.monotonic()
		ts_sync, tokens = ts, min(burst, tokens + (ts - ts_sync) * rate)
		val, tokens = (None, tokens - val) if tokens >= val else\
			((val - tokens) / rate, (tokens - val) if negative_tokens else tokens)
		val = (yield val) or 1


async def aio_await_wrap(res):
	'Wraps coroutine, callable that creates one or any other awaitable.'
	if not inspect.isawaitable(res) and callable(res): res = res()
	if inspect.isawaitable(res): res = await res
	return res

async def aio_task_cancel(task_list):
	'Cancel and await a task or a list of such, which can have empty values mixed-in.'
	if inspect.isawaitable(task_list): task_list = [task_list]
	task_list = list(filter(None, task_list))
	for task in task_list:
		with cl.suppress(asyncio.CancelledError): task.cancel()
	for task in task_list:
		with cl.suppress(asyncio.CancelledError): await task

class aio_timeout:
	def __init__(self, timeout):
		loop = asyncio.get_running_loop()
		self._timeout, self._timeout_call = False, loop.call_at(
			loop.time() + timeout, self._timeout_set, asyncio.current_task() )
	def _timeout_set(self, task): self._timeout = task.cancel() or True
	async def __aenter__(self): return self
	async def __aexit__(self, err_t, err, err_tb):
		if err_t is asyncio.CancelledError and self._timeout: raise asyncio.TimeoutError
		self._timeout_call.cancel()


class StacklessContext:
	'''Like AsyncContextStack, but for tracking tasks that
		can finish at any point without leaving stack frames.'''

	def __init__(self, log): self.tasks, self.log = dict(), log
	async def __aenter__(self): return self
	async def __aexit__(self, *err):
		if self.tasks:
			task_list, self.tasks = self.tasks.values(), None
			await aio_task_cancel(task_list)
	async def close(self): await self.__aexit__(None, None, None)

	def add_task(self, coro, run_after=None):
		'Start task eating its own tail, with an optional success-only callback'
		task_id = None
		async def _task_wrapper(coro=coro):
			try:
				await aio_await_wrap(coro)
				if run_after:
					coro = run_after()
					await aio_await_wrap(coro)
			except asyncio.CancelledError: pass
			except Exception as err:
				self.log.exception('Background task failed: {} - {}', coro, str_repr(err_fmt(err), 200))
			finally:
				assert task_id is not None, task_id
				if self.tasks: self.tasks.pop(task_id, None)
		task = asyncio.create_task(_task_wrapper())
		task_id = id(task)
		self.tasks[task_id] = task
		return task
	add = add_task


class FixedOffsetTZ(dt.tzinfo):
	_offset = _name = None
	@classmethod
	def from_offset(cls, name=None, delta=None, hh=None, mm=None):
		self = cls()
		if delta is None: delta = dt.timedelta(hours=hh or 0, minutes=mm or 0)
		self._name, self._offset = name, delta
		return self
	def utcoffset(self, dt): return self._offset
	def tzname(self, dt): return self._name
	def dst(self, dt, ZERO=dt.timedelta(0)): return ZERO
	def __repr__(self): return '<FixedOffset {!r}>'.format(self._name)

TZ_UTC = FixedOffsetTZ.from_offset('UTC')

def datetime_to_float(dt, _ts0=dt.datetime(1970, 1, 1, tzinfo=TZ_UTC)):
	return (dt - _ts0).total_seconds()

def parse_iso8601( spec,
		tz_default=TZ_UTC, to_float=True, validate=False,
		_re=re.compile(
			r'(\d{4})-(\d{2})-(\d{2})(?:[T ](\d{2}):(\d{2}))?'
			r'(?::(?P<s>\d{2})(?:\.(?P<us>\d+))?)?\s*(?P<tz>Z|[-+]\d{2}:\d{2})?' ) ):
	m = _re.search(spec)
	if not m: raise ValueError(spec)
	if validate: return
	if m.group('tz'):
		tz = m.group('tz')
		if tz == 'Z': tz = TZ_UTC
		else:
			k = {'+':1,'-':-1}[tz[0]]
			hh, mm = ((int(n) * k) for n in tz[1:].split(':', 1))
			tz = FixedOffsetTZ.from_offset(hh=hh, mm=mm)
	else: tz = tz_default
	ts_list = list(m.groups()[:5])
	if not ts_list[3]: ts_list[3] = ts_list[4] = 0
	ts_list = it.chain( map(int, ts_list),
		[int(m.group('s') or 0), int(m.group('us') or 0)] )
	# Minutes, seconds, microseconds get discarded here!
	ts = dt.datetime.strptime(
		'{:04d}-{:02d}-{:02d} {:02d}:{:02d}:{:02d}.{:06d}'.format(*ts_list),
		'%Y-%m-%d %H:%M:%S.%f' )
	assert tz
	ts = ts.replace(tzinfo=tz)
	return ts if not to_float else datetime_to_float(ts)

def ts_iso8601(ts, ms=3, to_str=True, human=False, strip_date=None):
	if not isinstance(ts, dt.datetime):
		ts = ( dt.datetime.utcfromtimestamp(ts)
			if not human else dt.datetime.fromtimestamp(ts) )
	if not human: ts = ts.replace(tzinfo=TZ_UTC)
	if ts.year > 2030: raise ValueError(ts) # sanity check
	if not to_str: return ts
	if human:
		ts_fmt = '%Y-%m-%d %H:%M:%S'
		if strip_date:
			if strip_date is True: ts_fmt = ts_fmt[9:]
			else: # strip specified redundant or rolled-over (next) date
				tss, d0 = strip_date, ts.strftime('%Y-%m-%d')
				if not isinstance(tss, (dt.datetime, dt.date)):
					tss = dt.datetime.fromtimestamp(tss)
				for tss in [tss, tss + dt.timedelta(days=1)]:
					if tss.strftime('%Y-%m-%d') == d0: ts_fmt = ts_fmt[9:]
		ts = ts.strftime(ts_fmt)
		return ts[:-3] if ts.endswith(':00') else ts
	ts_ext = f'{ts.microsecond:06d}'[:ms]
	if ts_ext: ts_ext = f'.{ts_ext}'
	return ts.strftime('%Y-%m-%dT%H:%M:%S') + ts_ext + 'Z'

_short_ts_days = dict(
	y=365.25, yr=365.25, year=365.25,
	mo=30.5, month=30.5, w=7, week=7, d=1, day=1 )
_short_ts_s = dict(
	h=3600, hr=3600, hour=3600,
	m=60, min=60, minute=60,
	s=1, sec=1, second=1 )
def _short_ts_re():
	sub_sort = lambda d: sorted(
		d.items(), key=lambda kv: (kv[1], len(kv[0])), reverse=True )
	ts_re = ['^'] + [
		r'(?P<{0}>\d*{0}s?\s*)?'.format(k)
		for k, v in it.chain.from_iterable(
			map(sub_sort, [_short_ts_days, _short_ts_s]) ) ] + ['$']
	return re.compile(''.join(ts_re), re.I | re.U)
_short_ts_re = _short_ts_re()
_parse_int = lambda v: int(''.join(c for c in v if c.isdigit()) or 1)

def parse_duration(ts_str, to_float=True):
	try: delta = dt.timedelta(seconds=float(ts_str))
	except ValueError:
		m = _short_ts_re.search(ts_str)
		if not m or not any(m.groups()):
			raise ValueError(ts_str) from None
		delta = list()
		for units in _short_ts_days, _short_ts_s:
			val = 0
			for k, v in units.items():
				try:
					if not m.group(k): continue
					n = _parse_int(m.group(k))
				except IndexError: continue
				val += n * v
			delta.append(val)
		delta = dt.timedelta(*delta)
	return delta if not to_float else delta.total_seconds()

def repr_duration( ts, ts0=None,
		ext=True, units_max=2, units_res=None,
		_units=dict( h=3600, m=60, s=1,
			y=365.25*86400, mo=30.5*86400, w=7*86400, d=1*86400 ) ):
	delta = ts if ts0 is None else (ts - ts0)
	if ext is True: ext = 'ago' if delta < 0 else 'from now'
	res, s, n_last = list(), abs(delta), units_max - 1
	for unit, unit_s in sorted(_units.items(), key=op.itemgetter(1), reverse=True):
		val = math.floor(s / unit_s)
		if not val:
			if units_res == unit: break
			continue
		if len(res) == n_last or units_res == unit:
			val, n_last = round(s / unit_s), True
		res.append(f'{val:.0f}{unit}')
		if n_last is True: break
		s -= val * unit_s
	if not res: return '-'
	else:
		if ext: res.append(ext)
		return ' '.join(res)


def iter_gather(cls, cache=False):
	'''Auto-gathers iterator function result into cls.
		cache=True will memoize function, allowing *args only,
			and pass cache_track func as a second argument to all calls.
		cache_track usage:
			ct(d) - any shallow changes to adict "d" will drop result cache for this call.
			ct(d, 'key1 key2 ...'), ct(d, [k1, k2, ...])
				Any changes to specified keys of "d" will drop result cache for this call.
				If any of these keys have adict value, shallow changes to it will propagate.'''
	def _cls_wrapper(func):
		if cache: stats_k = func.__name__ if cache is True else str(cache)
		@ft.wraps(func)
		def _wrapper(self, *args, **kws):
			if not cache: return cls(func(self, *args, **kws))
			if kws: raise ValueError(kws)
			k = (func.__qualname__, *args)
			if k not in iter_gather.cache:
				cache_track = ft.partial(iter_gather_track, k)
				args = [cache_track, *args]
				iter_gather.cache[k] = cls(func(self, *args, **kws))
				iter_gather.cache_stats[stats_k, 'miss'] += 1
			else: iter_gather.cache_stats[stats_k, 'hit'] += 1
			return iter_gather.cache[k]
		return _wrapper
	return _cls_wrapper

def iter_gather_cb(cache_k, keys, k, v):
	if keys and k not in keys: return
	iter_gather.cache.pop(cache_k, None)

def iter_gather_track(cache_k, o, keys=None):
	if not isinstance(o, adict): raise TypeError(o)
	if isinstance(keys, str): keys = keys.split()
	o._cache_cb_add( cache_k,
		ft.partial(iter_gather_cb, cache_k, keys) )
	for k in keys or list():
		if isinstance(o.get(k), adict): iter_gather_track(cache_k, o[k])

iter_gather.cache, iter_gather.cache_stats = dict(), cs.Counter()


class adict(cs.UserDict):
	__slots__ = 'data', '_cache_cb'

	def __init__(self, *args, **kws):
		self._cache_cb = None
		super().__init__(*args, **kws)
		self._make(self)

	def _make(self, v):
		if v is self: v.update((k, self._make(v)) for k,v in v.items())
		elif type(v) is dict: v = adict(v)
		elif isinstance(v, (tuple, list)): v = type(v)(map(self._make, v))
		return v

	def _cache_cb_add(self, cb_k, cb):
		if self._cache_cb is None: self._cache_cb = dict()
		self._cache_cb[cb_k] = cb
	def _cache_cb_check(self, k, v=...):
		if not self._cache_cb: return
		for cb in self._cache_cb.values(): cb(k, v)
		self._cache_cb.clear()

	def __getattr__(self, k):
		if k not in self.__slots__: return self[k]
		return self.__getattribute__(k)
	def __setattr__(self, k, v):
		if k not in self.__slots__: self[k] = v
		return super().__setattr__(k, v)
	def __delattr__(self, k, v): del self[k]

	def __setitem__(self, k, v):
		super().__setitem__(k, v)
		self._cache_cb_check(k, v)
	def __delitem__(self, k):
		super().__delitem__(k)
		self._cache_cb_check(k)

class irc_name_dict(cs.UserDict):
	value_map = classmethod(
		lambda cls, names: cls((v, v) for v in names) )
	def add(self, name): self[name] = name
	def remove(self, name): del self[name]
	def __contains__(self, key): return key.lower() in self.data
	def __getitem__(self, k): return self.data[k.lower()]
	def __setitem__(self, k, v): self.data[k.lower()] = v
	def __delitem__(self, k): del self.data[k.lower()]



class IRCProtocolError(Exception): pass
class IRCProtocolArgsError(IRCProtocolError): pass
class IRCBridgeSignal(Exception): pass

class IRCProtocol:

	# Extensive lists of modes are copied from freenode to make clients happy
	feats_modes = 'DOQRSZaghilopswz CFILMPQSbcefgijklmnopqrstvz'
	feats_support = ( 'AWAYLEN=200 CASEMAPPING=ascii'
		' CHANLIMIT=#:512 CHANTYPES=# CHANMODES=eIbq,k,flj,CFLMPQScgimnprstz'
		' CHANNELLEN=80 ELIST=C NETWORK=rdircd NICKLEN=64'
		' PREFIX=(ov)@+ SAFELIST STATUSMSG=@+ TOPICLEN=390 USERLEN=32' ).split()

	@classmethod
	def factory_for_bridge(cls, rdircd):
		def _wrapper():
			try: return cls(rdircd)
			except Exception as err:
				log = get_logger('rdircd.irc.factory')
				log.exception('Failed to initialize ircd protocol: {}', err_fmt(err))
				log.critical('Stopping daemon due to unhandled protocol error')
				rdircd.loop.stop()
		return _wrapper

	def __init__(self, rdircd):
		self.bridge, self.conf = rdircd, rdircd.conf
		self.log = get_logger('rdircd.irc.init')
		self.transport, self.buff, self.recv_queue = None, b'', asyncio.Queue()
		self._cmd_cache, self.st = dict(), adict(
			nick=None, user=None, pw=None, pw_hash=None,
			host=None, auth=False, cap_neg=False, away=None,
			chans=irc_name_dict() )
		if self.conf.irc_password:
			salt = os.urandom(8)
			self.st.pw_hash = salt, hashlib.blake2b(
				self.conf.irc_password.encode(), salt=salt ).digest()


	def connection_made(self, tr):
		host, port = tr.get_extra_info('peername')[:2]
		conn_id = tuple_hash([host, port], 3)
		self.log_proto = get_logger(f'proto.irc.{conn_id}')
		self.log_proto.debug( '--- -conn- {} {} {}',
			host, port, conn_id, extra=('---', f'conn {host} {port}') )
		self.log = get_logger(f'rdircd.irc.{conn_id}')
		self.log.debug('Connection from {} {} [{}]', host, port, conn_id)
		self.transport, self.st.host = tr, host
		self.send(0, 'NOTICE * :*** rdircd ready')
		self.bridge.irc_conn_new(self)
		self.bridge.cmd_delay(self.recv_queue_proc)

	def data_received(self, data):
		self.buff += data
		while b'\n' in self.buff:
			line, self.buff = self.buff.split(b'\n', 1)
			if not line.strip(): continue
			line_len, line_repr = self._repr_bin(line, True)
			self.log_proto.debug( '<<  [{} {}] {}',
				self.st.nick or '---', line_len, line_repr, extra=('<< ', line) )
			if not line.strip(): continue
			if self.recv_queue: self.recv_queue.put_nowait(line)
			else: self.log.error('Data after recv queue stopped: {!r}', line)

	def eof_received(self): pass
	def connection_lost(self, err):
		reason = err or 'closed cleanly'
		if isinstance(reason, Exception): reason = err_fmt(reason)
		self.log_proto.debug('--- -close- :: {}', reason, extra=('---', 'close'))
		self.log.debug('Connection lost: {}', reason)
		if self.recv_queue: self.recv_queue.put_nowait(StopIteration)
		self.bridge.irc_conn_lost(self)

	def data_send(self, data):
		data_len, data_repr = self._repr_bin(data, True)
		self.log_proto.debug( ' >> [{} {}] {}',
			self.st.nick or '---', data_len, data_repr, extra=(' >>', data) )
		self.transport.write(data)


	def _repr_bin(self, data, prefix=False, max_len=None, ext=' [{data_len}]'):
		'Binary-only version of str_repr().'
		if isinstance(data, str): data = data.encode()
		if max_len is None: max_len = self.conf.debug_proto_cut
		data_len, data_repr, ext_len = f'{len(data):,d}', repr(data)[2:-1], len(ext)
		if max_len > 0 and len(data_repr) > max_len:
			data_len = f'{max_len}/{data_len}'
			data_repr = data_repr[:max_len - ext_len] + ext.format(data_len=data_len)
		return (data_len, data_repr) if prefix else data_repr

	def _parse(self, line):
		if isinstance(line, bytes): line = line.decode()
		m = adict(line=line, params=list())
		for k in '@tags', ':src':
			pre, k = k[0], k[1:]
			if line.startswith(pre):
				try: m[k], line = line.split(' ', 1)
				except ValueError:
					raise IRCProtocolLineError(line) from None
				line = line.lstrip(' ')
			else: m[k] = None
		while True:
			if line.startswith(':'):
				m.params.append(line[1:])
				break
			if ' ' in line:
				param, line = line.split(' ', 1)
				line = line.lstrip(' ')
			else: param, line = line, ''
			m.params.append(param)
			if not line: break
		if m.params: m.cmd, m.params = m.params[0].lower(), m.params[1:]
		else: raise IRCProtocolLineError(line)
		return m

	def send(self, line_or_code, *args, max_len=None, auto_split=True):
		line = line_or_code
		if isinstance(line, int): # code=0 only adds :host prefix
			code, line = line, f':{self.bridge.server_host}'
			if code: line += f' {code:03d} {self.st.nick or "*"}'
		if args: line += ' ' + ' '.join(map(str, args))
		if isinstance(line, str): line = line.encode()
		if max_len is None: max_len = self.conf.irc_len_hwm
		line = line.rstrip(b'\r\n')
		if b'\n' in line or len(line) > max_len:
			if auto_split:
				m = self._parse(line)
				if m.cmd in ['privmsg', 'notice']: return self.send_split_msg(m)
			if len(line) > max_len:
				self.log.info('Sending line with >{}B: {!r}', max_len, self._repr_bin(line))
		if b'\n' in line: raise IRCProtocolError(f'Line with newlines: {line!r}')
		line += b'\r\n'
		self.data_send(line)

	def send_split_msg(self, m):
		dst, line = m.params
		pre, max_len = f'{m.cmd.upper()} {dst}', self.conf.irc_len_lwm
		if m.src: pre = f'{m.src} {pre}'
		if '\n' in line:
			for line in line.split('\n'): self.send(pre, f':{line.rstrip()}')
			return
		line, ws = '', re.findall(r'(\S+)(\s*)', line)
		for w, sep in ws:
			if line.strip() and len(line) + len(w) > max_len:
				self.send(pre, f':{line.rstrip()}', auto_split=False)
				line = sep_last
			sep_last, line = sep, line + w + sep
		if line.strip(): self.send(pre, f':{line.rstrip()}', auto_split=False)

	async def recv_queue_proc(self):
		try:
			while True:
				line = await self.recv_queue.get()
				if line is StopIteration: break
				try: await self.recv(line)
				except Exception as err:
					self.log.exception(f'Failed to parse line: {line}')
		finally: self.recv_queue = None

	async def recv(self, line_raw):
		if isinstance(line_raw, str): line = line_raw
		else:
			try: line = line_raw.decode().strip()
			except UnicodeDecodeError:
				return self.log.error('Failed to decode line as utf-8: {!r}', self._repr_bin(line_raw))
		try: m = self._parse(line)
		except IRCProtocolLineError:
			return self.log.error('Line protocol error: {!r}', self._repr_bin(line_raw))
		cmd_cache = self._cmd_cache.get(m.cmd)
		if cmd_cache: cmd_func, cmd_ps_n = cmd_cache
		else:
			cmd_func, cmd_ps_n = getattr(self, f'recv_cmd_{m.cmd}', None), 0
			if cmd_func:
				args = list(inspect.signature(cmd_func).parameters.values())
				cmd_ps_n = len(args)
				if cmd_ps_n == 1 and args[0].annotation == 'msg': cmd_ps_n = None
				else: cmd_ps_n = cmd_ps_n - sum(1 for p in args if p.default is not p.empty), cmd_ps_n
			self._cmd_cache[m.cmd] = cmd_func, cmd_ps_n
		if not cmd_func:
			self.log.error('Unhandled cmd: {!r}', self._repr_bin(line_raw))
			return self.send(421, ':Unknown command')
		if not self.check_access(m.cmd):
			return self.log.error('Out-of-order cmd: {!r}', self._repr_bin(line_raw))
		if cmd_ps_n is None: await aio_await_wrap(cmd_func(m))
		else:
			(a, b), n = cmd_ps_n, len(m.params)
			if not a <= n <= b:
				self.log.error( 'Command/args'
					' mismatch [{} vs {}-{}]: {!r}', n, a, b, self._repr_bin(line) )
				return self.send(461, ':Incorrect command parameters')
			try: await aio_await_wrap(cmd_func(*m.params))
			except Exception as err:
				self.send(400, m.cmd.upper(), f':BUG - Internal Error - {err_fmt(err)}')
				self.log.exception('Error processing message: {}', m)

	def check_access(self, cmd):
		if not self.st.auth:
			res = cmd in ['cap', 'user', 'nick', 'pass', 'quit', 'ping']
			if not res: self.send(451, ':You have not registered')
			return res
		elif cmd in ['user', 'pass']:
			self.send(462, ':You may not reregister')
			return False
		if self.st.cap_neg:
			# No commands other than auth allowed until capability negotiation ends
			# Note that negotiation can be skipped entirely too
			return cmd in ['cap', 'quit', 'ping']
		return True # any commands allowed outside of phases above

	# chan_spec=#lower(some-channel), chan_name=lower(some-channel)
	_csc = lambda c: c.startswith('#')
	chan_spec_check = staticmethod(_csc)
	chan_spec = staticmethod(
		lambda name,_csc=_csc: name if _csc(name) else f'#{name.lower()}' )
	chan_name = staticmethod(
		lambda chan,_csc=_csc: (chan if not _csc(chan) else chan[1:]).lower() )


	def recv_cmd_ping(self, server, server_dst=None):
		self.send(f'PONG {self.bridge.server_host}')

	def recv_cmd_cap(self, sub, caps=''):
		sub = sub.lower()
		if sub == 'ls':
			self.send(0, 'CAP * LS :')
			if caps == '302': self.st.cap_neg = True
		elif sub == 'list': self.send(0, f'CAP * LIST :')
		elif sub == 'req':
			self.st.cap_neg = True
			reject = set(c for c in caps.split() if not c.startswith('-'))
			if reject: self.send(0, f'CAP * NAK :{caps}')
			else: self.send(0, f'CAP * ACK :{caps}')
		elif sub == 'end': self.st.cap_neg = False

	def recv_cmd_pass(self, pw):
		self.st.pw = pw
		self.check_auth_done()
	def recv_cmd_user(self, name, a, b, real_name):
		self.st.update(user=name, real_name=real_name)
		self.check_auth_done()
	def recv_cmd_nick(self, nick):
		if not re.search(r'^[a-zA-Z-._]+$', nick):
			return self.send(432, nick, ':Erroneus nickname')
		if self.bridge.cmd_conn(nick):
			return self.send(433, nick, ':Nickname is already in use')
		self.st.nick = nick
		if self.st.auth and self.st.nick:
			self.send(f':{self.st.nick} NICK {nick}')
		self.check_auth_done()

	def check_auth_done(self):
		# Delay is to avoid trivial bruteforcing
		self.bridge.cmd_delay('irc_auth', self.check_auth_done_delayed)
	def check_auth_done_delayed(self):
		if self.st.auth: return
		if not (self.st.nick and self.st.user): return
		if self.st.pw_hash:
			salt, pw_hash = self.st.pw_hash
			if not secrets.compare_digest( pw_hash,
					hashlib.blake2b((self.st.pw or '').encode(), salt=salt).digest() ):
				return self.send(464, ':Password incorrect')
		self.st.auth = True
		self.send(0, 'NOTICE * :*** registration completed')
		self.send(1, f':Welcome to the rdircd discord-irc bridge, {self.st.nick}')
		self.send(2,
			f':Your host is {self.bridge.server_host},'
			f' running rdircd {self.bridge.server_ver}' )
		self.send(3, ':This server was created at {}'.format(
			self.bridge.server_ts.strftime('%Y-%m-%d %H:%M:%S UTC') ))
		self.send(4, f'{self.bridge.server_host} rdircd-{self.bridge.server_ver} {self.feats_modes}')
		self.send_feats()
		self.send_stats()
		self.send_motd()

	def send_feats(self, msg_feats_max=10, msg_len_max=200):
		feat_line, ext = list(), ':are supported by this server'
		for feat in it.chain(self.feats_support, [None]):
			if feat: feat_line.append(feat)
			n, msg_len = len(feat_line), sum((len(f)+1) for f in feat_line)
			if feat_line and (not feat or n >= msg_feats_max or msg_len >= msg_len_max):
				self.send(5, ' '.join(feat_line), ext)
				feat_line.clear()

	def send_stats(self):
		s = self.bridge.irc_conn_stats()
		self.send(251, f':There are {s.auth} users and 0 invisible on {s.servers} server(s)')
		self.send(252, f'{s.op} :IRC Operators online')
		self.send(253, f'{s.unknown} :unknown connection(s)')
		self.send(254, f'{s.chans} :channels formed')
		self.send(255, f':I have {s.total} client(s) and {s.servers} server(s)')
		self.send( 265, f'{s.total} {s.total_max}',
			f':Current local users {s.total}, max {s.total_max}' )
		self.send( 266, f'{s.total} {s.total_max}',
			f':Current global users {s.total}, max {s.total_max}' )

	def send_motd(self):
		motd = self.conf.irc_motd_file_path
		if motd:
			try: motd = pl.Path(self.conf.irc_motd_file_path).read_text()
			except FileNotFoundError: motd = ''
		if not motd: return self.send(422, ':MOTD File is missing')
		self.send(375, f':- {self.bridge.server_host} Message of the day -')
		for line in motd.splitlines(): self.send(372, f':- {line}')
		self.send(376, ':End of /MOTD command')

	def recv_cmd_quit(self, reason=None):
		self.send('QUIT :Client quit')
		self.send('ERROR :Closing connection (client quit)')
		self.transport.close()

	def req_chan_info(self, chan, cm=None, check=True):
		if not self.chan_spec_check(chan):
			return self.send(403, chan, ':No such channel')
		if not cm: cm = self.bridge.cmd_chan_map()
		c = cm.get(self.chan_name(chan))
		if c: return c
		if check: self.send(403, chan, ':No such channel')

	def recv_cmd_join(self, chan, key=None):
		if chan == '0': return self.recv_cmd_part(','.join(self.st.chans.values()))
		chan_list, chan_map = chan.split(','), self.bridge.cmd_chan_map()
		for chan in chan_list: self.cmd_join(chan, cm=chan_map)

	def cmd_join(self, chan, cm=None):
		if not cm: cm = self.bridge.cmd_chan_map()
		c = self.req_chan_info(chan, cm=cm, check=False)
		name = c.name if c else self.chan_name(chan)
		self.send(f':{self.st.nick} JOIN {chan}')
		self.send_topic(chan, c=c)
		self.send_names(chan, own=True, c=c)
		self.send(f'MODE {chan} +v {self.st.nick}')
		self.st.chans.add(name)

	def recv_cmd_part(self, chan, reason=None):
		chan_list, chan_map = chan.split(','), self.bridge.cmd_chan_map()
		for chan in chan_list:
			c = self.req_chan_info(chan, cm=chan_map, check=False)
			name = c.name if c else self.chan_name(chan)
			if name not in self.st.chans:
				self.send(442, chan, ':You are not on that channel')
			else:
				self.st.chans.remove(name)
				self.send(f':{self.st.nick} PART {chan}')

	async def recv_cmd_topic(self, chan, topic=None):
		c = self.req_chan_info(chan)
		if not c: return self.send(403, chan, ':No such channel')
		if not topic:
			self.send_topic(chan)
			return await self.bridge.irc_topic_cmd(self, c.name)
		try: await self.bridge.irc_topic_cmd(self, c.name, topic)
		except IRCBridgeSignal as err: self.send(482, chan, f':{err}')

	def send_topic(self, chan, c=...):
		if c is ...: c = self.req_chan_info(chan)
		if not (c and c.topic): self.send(331, chan, ':No topic is set')
		else:
			topic = str_repr(c.topic, max_len=self.conf.irc_len_topic, len_bytes=True)
			self.send(332, chan, f':{topic}')
			topic_src = c.get('topic_src')
			if topic_src: self.send(333, chan, topic_src.nick, int(topic_src.ts))

	def recv_cmd_names(self, chan):
		chan_list = chan.split(',')
		for chan in chan_list: self.send_names(chan)

	def send_names(self, chan, own=False, c=..., msg_len_max=200):
		if c is ...: c = self.req_chan_info(chan)
		name_line, names = list(), self.bridge.cmd_chan_names(c.name) if c else list()
		for name in it.chain(names, [None]):
			if name:
				if irc_name_eq(name, self.st.nick): own = False
				name_line.append(name)
			elif own and self.st.nick: name_line.append(self.st.nick)
			if name_line and (
					not name or sum(len(n)+1 for n in name_line) > msg_len_max ):
				self.send(353, '=', chan, ':' + ' '.join(name_line))
				name_line.clear()
		self.send(366, chan, ':End of /NAMES list')

	def recv_cmd_mode(self, target, mode=None, mode_args=None):
		if self.chan_spec_check(target):
			chan = target
			c = self.req_chan_info(chan, check=False)
			if self.conf.irc_chan_modes: self.send(324, chan, '+cnrt')
			if c: chan_ts = int(c.ts_created)
			else:
				if self.chan_name(chan) not in self.st.chans:
					return self.send(403, chan, ':No such channel')
				chan_ts = int(time.time())
			if self.conf.irc_chan_modes: self.send(329, chan, chan_ts)
		else:
			if not irc_name_eq(target, self.st.nick):
				return self.send(502, ':No access to modes of other users')
			self.send(221, ':+w')

	def recv_cmd_away(self, msg=None):
		self.st.away = msg or None
		if self.st.away: self.send(306, ':You have been marked as being away')
		else: self.send(305, ':You are no longer marked as being away')

	def recv_cmd_list(self, chan=None, cond=None):
		self.send(321, 'Channel :Users  Name')
		for c in self.bridge.cmd_chan_map().values():
			names = self.bridge.cmd_chan_names(c.name)
			topic = str_repr(c.topic, max_len=self.conf.irc_len_topic, len_bytes=True)
			self.send(322, self.chan_spec(c.name), len(names), f':{topic}')
		self.send(323, ':End of /LIST')

	def recv_cmd_motd(self, target=None): self.send_motd()

	def recv_cmd_version(self, target=None):
		self.send(351, self.bridge.server_ver, 'rdircd', ':rdircd discord-to-irc bridge')
		self.send_feats()

	def recv_cmd_privmsg(self, target, text):
		self.cmd_msg(self.st.nick, target, text, from_self=True)

	def recv_cmd_notice(self, target, text):
		self.cmd_msg(self.st.nick, target, text, notice=True, from_self=True)

	def cmd_msg(self, src, target, text, notice=False, from_self=False):
		'''Handler for messages posted from irc.
			With notice=True message is only handled in irc, without proxying it to discord.'''
		msg_type = 'PRIVMSG' if not notice else 'NOTICE'
		if self.chan_spec_check(target):
			chan, name = target, self.chan_name(target)
			if not notice: c = self.req_chan_info(chan)
			else: c = self.bridge.cmd_chan_map().get(name)
			if not c: return
			if from_self and c.t == c.t.mon:
				self.send( f':monitor NOTICE {chan} :WARNING:'
					' this is one of the monitor-channels, msgs posted here are not proxied to discord' )
			for conn in self.bridge.cmd_chan_conns(name):
				if from_self and conn is self: continue
				if name not in conn.st.chans: self.cmd_join(chan) # from chan_auto_join_re
				conn.send(f':{src} {msg_type} {chan} :{text}')
			if not notice: self.bridge.irc_msg(self, chan, text)
		else:
			conn = self.bridge.cmd_conn(target)
			if not conn:
				if not notice: self.send(401, target, ':No such nick/channel')
			else: conn.send(f':{src} {msg_type} {target} :{text}')

	def cmd_msg_synth(self, src, chan, text, notice=False, direct=False):
		'''Synthetic PRIVMSG which avoids any self-reaction loops like notices
				or sending it back to discord and such - for generating one-way messages to irc chanels.
			Channel target must be prefixed by #. direct=True msg only goes to self.'''
		if not self.chan_spec_check(chan): raise ValueError(chan)
		name, msg_type = self.chan_name(chan), 'PRIVMSG' if not notice else 'NOTICE'
		if direct: # on this conn only
			if ( name not in self.st.chans and
					self.conf._irc_chan_auto_join_re.search(name) ):
				self.cmd_join(chan)
			return self.send(f':{src} {msg_type} {chan} :{text}')
		cm = self.bridge.cmd_chan_map()
		if not cm.get(name): return
		for conn in self.bridge.cmd_chan_conns(name):
			if name not in conn.st.chans: self.cmd_join(chan, cm=cm) # from chan_auto_join_re
			conn.send(f':{src} {msg_type} {chan} :{text}')

	def cmd_msg_self(self, src, text, notice=True):
		msg_type = 'PRIVMSG' if not notice else 'NOTICE'
		self.send(f':{src} {msg_type} {self.st.nick} :{text}')

	# Some of following user/server/channel-info cmds
	#  can be (ab)used to provide discord user/channel info.
	# Currently this isn't stored or queried anywhere,
	#  so no need for these beyond stubs for what ZNC and such use.

	def recv_cmd_userhost(self, nick):
		if irc_name_eq(nick, self.st.nick):
			self.send(302, f':{nick}=+~{self.st.user}@{self.st.host}')
		else: self.send(401, nick, ':No such nick/channel')

	def recv_cmd_who(self, name):
		if re.search(r'^[#@%]\d+$', name):
			self.bridge.cmd_delay(self.bridge.cmd_info(self, name[0], name[1:]))
		else:
			conn = self.bridge.cmd_conn_map().get(name)
			if conn:
				self.send( 352, '*', conn.st.user, conn.st.host,
					self.bridge.server_host,conn.st.nick, 'H', f':0 {conn.st.nick}' )
		self.send(315, name, ':End of /WHO list.')

	# recv_cmd_whois
	# recv_cmd_whowas
	# recv_cmd_admin
	# recv_cmd_time
	# recv_cmd_stats
	# recv_cmd_info



class DiscordError(Exception): pass
class DiscordAbort(DiscordError): pass
class DiscordHTTPError(DiscordError): pass
class DiscordSessionError(Exception): pass


class Discord:

	def __init__(self, rdircd):
		self.bridge, self.conf = rdircd, rdircd.conf
		self.log = get_logger('rdircd.discord')
		self._repr = ft.partial(str_repr, max_len=self.conf.debug_msg_cut)

	async def __aenter__(self):
		if not ( self.conf.get('auth_email')
				and self.conf.get('auth_password') ):
			self.log.error('Disabling discord due to missing access credentials')
			self.session = None
		else:
			s = self.session = DiscordSession(self)
			s.task = asyncio.create_task(s.run_async())
		self.flake_id = (int.from_bytes(os.urandom(2), 'big') & 0x3ff) << 12
		self.flake_n, self.msg_confirms = 0, dict()
		self.user_mention_cache = cs.defaultdict(irc_name_dict)
		self.user_mention_cache_ts_cleanup = 0
		return self

	async def __aexit__(self, *err):
		if self.session: await aio_task_cancel(self.session.task)

	def connect(self):
		if self.session: self.session.connect()
	def disconnect(self):
		if self.session: self.session.disconnect()

	def flake_parse(self, flake):
		if not flake: return None
		try: return (int(flake) >> 22)/1e3 + 1420070400
		except ValueError: return None
	def flake_build(self, ts):
		flake = self.flake_n | self.flake_id | int((ts - 1420070400) * 1e3) << 22
		self.flake_n = (self.flake_n + 1) % 0xfff
		return str(flake)

	@property
	def st(self):
		try:
			if not self.session: raise KeyError
			return self.session.st
		except KeyError: return adict(guilds=dict())

	def irc_chan_name(self, cc):
		return f'#{self.bridge.cache.did_chan.get(cc.did)}'

	def cmd_chan_map_update(self):
		'Discord channel changes signal, to rebuild various mappings as necessary.'
		list(self.bridge.cmd_chan_map()) # enough to trigger re-caching

	async def cmd_history(self, gg, cc, ts, lwm=70, hwm=90):
		if not self.session: return list()
		msg_list, flake = list(), self.flake_build(ts)
		while True:
			msg_batch = await self.session.req(
				f'channels/{cc.id}/messages',
				params=dict(after=flake, limit=hwm) )
			flake_last = flake
			for m in map(adict, msg_batch or list()):
				line, tags = self.session.op_msg_parse(m, gg)
				if not line: continue # joins/parts/pins and such
				# Note: parse_iso8601(m.timestamp) == flake_parse(m.id)
				self.cmd_user_cache(gg.id, m.author.id, m.author.username, replace=False)
				msg_list.append(adict( nick=m.author.username,
					line=line.strip(), tags=tags, ts=self.flake_parse(m.id) ))
				if int(m.id) > int(flake): flake = m.id
			if flake == flake_last or len(msg_list) < lwm: break
		return sorted(msg_list, key=op.itemgetter('ts'))

	async def cmd_info_dump(self, info_url):
		if not self.session: return f'No info for {info_url}: no discord session'
		try: info = await self.session.req(info_url)
		except DiscordHTTPError as err: return f'No info for {info_url}: {err}'
		return data_repr(info)

	def cmd_msg_recv( self, cc, nick, line,
			tags=None, flake=None, nonce=None, notice=None, skip_monitor=False ):
		self.log.debug('MSG: <<  :: {} {} :: {} :: {} {}', cc.gid, cc.name, nick, line, tags or '')
		if nonce and flake and not ( self.conf.discord_thread_msgs_in_parent_chan
				and tags.get('_prefix', '').startswith(self.conf.discord_thread_id_prefix) ):
			# Thread-prefixed msgs can be mirrored to two chans, hence the check/skip here
			fut = self.msg_confirms.pop(nonce, None)
			if fut:
				self.log.debug('MSG: confirm nonce={} flake={}', nonce, flake)
				return fut.set_result(flake)
		self.bridge.cmd_msg_discord( cc, nick, line,
			tags, notice=notice, ts=self.flake_parse(flake), skip_monitor=skip_monitor )

	async def cmd_msg_send(self, cc, line):
		if not self.session: raise IRCBridgeSignal('no-discord-conn')
		try:
			if ( self.conf.discord_thread_redirect_prefixed_responses_from_parent_chan
					and line.split(None, 1)[0].startswith(self.conf.discord_thread_id_prefix) ):
				c_tid, line = line.split(None, 1)
				cc = cc.threads.get(c_tid.lower())
				if not cc: raise IRCBridgeSignal(f'no-such-thread {c_tid}')

			nonce = self.flake_build(time.time())
			self.log.debug('MSG:  >> :: {} {} {} :: {}', cc.gid, cc.name, nonce, line)
			try:
				res = None
				async with aio_timeout(self.conf.discord_msg_confirm_timeout):
					line = await self.cmd_msg_send_annotate(cc, line)
					res = asyncio.create_task(self.session.req(
						f'channels/{cc.id}/messages',
						m='post', json=dict(content=line, nonce=nonce) ))
					fut = self.msg_confirms[nonce] = asyncio.Future()
					res = asyncio.gather(fut, res)
					flake_gw, res = await res
			except asyncio.TimeoutError:
				if res: await aio_task_cancel(res)
				raise IRCBridgeSignal('msg-confirm-timed-out')
			finally: self.msg_confirms.pop(nonce, None)
			try: flake_res = res['id']
			except: raise DiscordError(f'Invalid response: {res}')
			if flake_gw != flake_res:
				self.log.warning( 'Same-nonce sent/received'
					' msg-id mismatch: {} != {}', flake_gw, flake_res )
			self.log.debug('Sending of msg {} confirmed: {}', flake_res, self._repr(line))

		except Exception as err:
			if isinstance(err, IRCBridgeSignal): raise
			err_str = err_fmt(err)
			self.log.exception('Failed sending discord msg: {}', err_str)
			raise IRCBridgeSignal(err_str)

	async def cmd_msg_send_annotate(self, cc, line):
		'''Translate IRC nick mentions matched by
				"discord_msg_mention_re" replaced with Discord mention-tags, if any.
			Either returns line with all mentioned translated or fails with DiscordError.'''
		# Regexp group replacements are made from the end to start,
		#  with line/tag parts lists containing reversed str parts to reassemble.
		# https://discord.com/developers/docs/reference#message-formatting
		if not self.conf._discord_msg_mention_re: return line
		line_parts, nick_idx = [line], self.conf._discord_msg_mention_re.groupindex['nick']
		matches = list(self.conf._discord_msg_mention_re.finditer(line))
		for n, m in enumerate(reversed(matches)):
			line, tag, (a, b) = line_parts.pop(), m.group(), m.span()
			mx = self.conf._discord_msg_mention_re_ignore.search(tag)
			self.log.debug(
				'Discord mention match [{}/{}]: {!r} [{}-{}]{}',
				n+1, len(matches), tag, a, b, ' + ignore-pattern match' if mx else '' )
			tag_parts = ( self.cmd_msg_annotate_ignore_strip(tag, mx)
				if mx else await self.cmd_msg_annotate_translate_tag(cc, m, nick_idx) )
			line_parts.extend([line[b:], *tag_parts, line[:a]])
		return ''.join(reversed(line_parts))

	def cmd_msg_annotate_ignore_strip(self, tag, mx):
		'Strips all capture groups in match from tag-string'
		tag, subs = [tag], (mx.span(n) for n, s in enumerate(mx.groups(), 1))
		for a, b in sorted(subs, reverse=True):
			part = tag.pop()
			tag.extend([part[b:], part[:a]])
		return tag

	async def cmd_msg_annotate_translate_tag(self, cc, m, nick_idx):
		tag, (a, b) = m.group(), m.span()
		nick, (na, nb) = m.group(nick_idx), m.span(nick_idx)
		if not (tag and nick): tag = [tag]
		else:
			subs = list( (ga-a, gb-a, '') for ga, gb in
				(m.span(n) for n, group in enumerate(m.groups(), 1) if n != nick_idx) )
			if self.conf.discord_msg_mention_irc_decode:
				# This should make irc nicks usable for mention-tags as-is,
				#  and fix matching e.g. discord names with spaces for default regexp.
				nick = self.bridge.irc_name_revert(nick) or nick
			uid = self.user_mention_cache[cc.gid].get(nick)
			if uid: # exact match
				nick = f'<@{uid}>'
				self.cmd_user_cache(cc.gid, uid, replace=False)
			else:
				user_map = await self.session.ws_req_users_query(cc.gid, nick, 6)
				if not user_map: raise IRCBridgeSignal(f'{nick}=no-matches')
				elif len(user_map) > 1:
					nicks = list(user_map.values())
					nicks = ' '.join(map(repr, nicks[:5])) + (' +' if len(nicks) > 5 else '')
					raise IRCBridgeSignal(f'{nick}=[{nicks}]')
				else: # successful server-lookup with unique result
					uid = next(iter(user_map.keys()))
					self.cmd_user_cache(cc.gid, uid, nick, replace=False, query=True)
					nick = f'<@{uid}>'
			tag = [tag]
			for sa, sb, s in sorted(subs + [(na-a, nb-a, nick)], reverse=True):
				part = tag.pop()
				tag.extend([part[sb:], s, part[:sa]])
		return tag

	def cmd_user_cache(self, gid, uid, name=None, replace=True, query=False):
		'''Updates user_mention_cache for discord-user-id, as nick_or_query=uid mapping.
			name is auto-translated to irc nick, unless query=True.
			name=None replace=True deletes the entry.
			name=None replace=False resets entry timestamp, so it stays for timeout from now.'''
		users, ts = self.user_mention_cache[gid], time.monotonic()
		uid_key = f'\0{uid}' if not query else f'\t{uid}' # so that queries can co-exist with users
		if not replace and uid_key in users:
			if not name: users[uid_key] = users[uid_key][0], ts
			return
		name_old, ts_old = users.pop(uid_key, (None, 0))
		# There can be two users with exactly same username, esp. with bridge-bots
		if name_old: users.pop(name_old, None)
		if not name: return
		if not query: name = self.bridge.irc_name(name)
		users[name], users[uid_key] = uid, (name, ts)
		if ( (ts - self.user_mention_cache_ts_cleanup)
				> self.conf.discord_user_mention_cache_timeout / 2 ):
			ts -= self.conf.discord_user_mention_cache_timeout
			for uid_key in list(users.keys()):
				if uid_key[0] not in '\0\t' or uid_key not in users: continue
				if users[uid_key][1] < ts: self.cmd_user_cache(gid, uid_key[1:])

	def cmd_chan_rename(self, cc, name_old=None):
		name_new = self.irc_chan_name(cc)
		name_old = self.bridge.irc_name(name_old).lower()
		self.bridge.cmd_msg_discord( cc, None,
			f'-----== Discord channel renamed: {name_old} -> {name_new} ==-----' )

	def cmd_chan_thread(self, cc):
		# Idea behind tag prefix is to allow sending msgs from parent channel to a prefixed thread
		self.bridge.cmd_msg_discord( cc, None,
			f'[{cc.tid}] --- Thread channel created: {self.irc_chan_name(cc)}' )

	def cmd_guild_event(self, gid, msg):
		'Report non-discord-channel event in global/guild monitor channels, e.g. user bans'
		if gid == 1: guild_prefix = ''
		else:
			gg = self.st.guilds.get(gid)
			guild_prefix = '[' + (gg.name if gg else f'%{m.guild_id}') + '] '
		self.bridge.cmd_msg_monitor(
			f'{self.conf.irc_prefix_guild_event}{guild_prefix}{msg}', gid=gid )



class DiscordSession:

	# See https://discord.com/developers/docs/change-log
	api_ver = 9

	class c(enum.IntEnum):
		dispatch = 0
		heartbeat = 1
		identify = 2
		status_update = 3
		voice_state_update = 4
		resume = 6
		reconnect = 7
		request_guild_members = 8
		invalid_session = 9
		hello = 10
		heartbeat_ack = 11
		request_sync = 12
		client_disconnected = 13
		request_sync_chan = 14

		unknown_error = 4000
		unknown_opcode = 4001
		decode_error = 4002
		not_authenticated = 4003
		authentication_failed = 4004
		already_authenticated = 4005
		invalid_seq = 4007
		rate_limited = 4008
		session_timeout = 4009
		invalid_shard = 4010
		sharding_required = 4011

		oneshot = 10_000

	class c_chan_type(enum.IntEnum):
		# https://discord.com/developers/docs/resources/channel#channel-object-channel-types
		text = 0
		private = 1
		voice = 2
		private_group = 3
		group = 4 # header for a group of channels
		news = 5 # announcements channels
		store = 6
		thread_news = 10 # threads in news channels
		thread = 11
		thread_private = 12 # invite-only threads
		stage = 13

	class c_msg_type(enum.IntEnum):
		# https://discord.com/developers/docs/resources/channel#message-object-message-types
		default = 0
		recipient_add = 1
		recipient_remove = 2
		call = 3
		channel_name_change = 4
		channel_icon_change = 5
		channel_pinned_message = 6
		guild_member_join = 7
		user_premium_guild_subscription = 8
		user_premium_guild_subscription_tier_1 = 9
		user_premium_guild_subscription_tier_2 = 10
		user_premium_guild_subscription_tier_3 = 11
		channel_follow_add = 12
		guild_discovery_disqualified = 14
		guild_discovery_requalified = 15
		guild_discovery_grace_period_initial_warning = 16
		guild_discovery_grace_period_final_warning = 17
		thread_created = 18
		reply = 19 # inline reply msg, was type=default with old api
		application_command = 20
		thread_starter_message = 21
		guild_invite_reminder = 22

		# Negative values are internal types
		bot_embeds = -1001

	class c_rel_type(enum.IntEnum):
		none = 0
		friend = 1
		blocked = 2
		friend_req_in = 3
		friend_req_out = 4
		friend_implicit = 5

	c_msg_tags = enum.Enum('c_msg_tags', 'user chan role emo ts everyone other')
	c_msg_tags_ts_fmts = dict(
		t='%H:%M', T='%H:%M:%S', d='%Y%m%d', D='%m %B %Y',
		f='%Y%m%d %H:%M:%S', F='%c', R=repr_duration )

	def __init__(self, discord):
		self.discord, self.conf = discord, discord.conf
		self.api_url = self.conf.discord_api_url.format(api_ver=self.api_ver)
		self.log = get_logger(f'rdircd.discord')
		self.log_ws = get_logger(f'proto.ws')
		self.log_http = get_logger(f'proto.http')
		self.log_http_reqres = get_logger(f'proto.http.reqres')
		self._repr = ft.partial(str_repr, max_len=self.conf.debug_proto_cut)

	def get_auth(self, k, default=ValueError):
		try: return self.conf.get(f'auth_{k}')
		except AttributeError as err:
			if default is ValueError: raise
			return default

	async def __aenter__(self):
		if not (self.get_auth('email') and self.get_auth('password')):
			raise DiscordSessionError('Missing account auth credentials')
		self.ctx, self.tasks = cl.AsyncExitStack(), StacklessContext(self.log)
		aiohttp_opts = adict(timeout=aiohttp.ClientTimeout(
			connect=self.conf.discord_http_timeout_conn,
			sock_connect=self.conf.discord_http_timeout_conn_sock ))
		if self.conf.debug_proto_aiohttp:
			aiohttp_opts.trace_configs = [setup_aiohttp_trace_logging(self.log_http_reqres)]
		self.http = await self.ctx.enter_async_context(aiohttp.ClientSession(**aiohttp_opts))
		self.ws_ctx = self.ws = self.ws_tasks = self.ws_handlers = self.ws_nonces = None
		self.ws_closed, self.ws_closed_clean = asyncio.Event(), asyncio.Event()
		self.ws_closed_clean.set()
		self.rate_limits = adict()
		self.st = adict(guilds={1: adict(
			id=1, name='me', ts_joined=0, kh='me', chans=dict(), roles=dict() )})
		self.st.me = self.st.guilds[1]
		self.auth_token, self.auth_token_manual = (
			self.get_auth('token'), self.get_auth('token_manual') )
		self.ws_enabled = False
		return self

	async def __aexit__(self, *err):
		if self.ws_enabled:
			self.ws_enabled.cancel()
			self.ws_enabled = None
		if self.ws_ctx: await self.ws_ctx.aclose()
		if self.ctx: await self.ctx.aclose()
		if self.tasks: await self.tasks.close()

	async def run(self):
		self.log.debug('Initializing discord session...')
		try: await asyncio.Future() # run forever
		except asyncio.CancelledError: pass
		self.log.debug('Finished')

	async def run_async(self):
		async with self: await self.run()

	def connect(self):
		if self.ws_enabled and not self.ws_enabled.done(): return
		task = self.ws_enabled = asyncio.create_task(self.ws_connect_loop())
		return self.tasks.add(task)
	def disconnect(self):
		if self.ws_enabled:
			self.ws_enabled.cancel()
			self.ws_enabled = None
		return self.tasks.add(self.ws_close())

	def state(self, st):
		'''This is purely informative, and should never
			actually be checked - use class flags for that, not strings here.'''
		st_old, self.st.state = self.st.get('state', 'none'), st
		if st == st_old: return
		self.log_ws.debug( '--- state: {} -> {}',
			st_old, st, extra=('---', f'st {st_old} -> {st}') )
		self.log.info('State: {} -> {}', st_old, st)


	### Regular HTTP requests and OAuth2 stuff

	async def rate_limit_wrapper(self, route, req_func):
		# Discord also returns proactive X-Rate-Limit headers, but these are
		#  not used here - shouldn't be needed, as simple client is unlikely to bump into them
		req_limit_defaults = 1, None
		while True:
			ts = time.time()
			req_limit, req_limit_ts = self.rate_limits.get(route) or req_limit_defaults
			if req_limit_ts and ts > req_limit_ts: req_limit = 1
			if req_limit <= 0 and req_limit_ts and req_limit_ts > ts:
				delay = req_limit_ts - ts
				self.log.debug('Rate-limiting request on route {!r}: delay={:,.1f}s', route, delay)
				await asyncio.sleep(delay + self.conf.discord_http_delay_padding)
			res = await req_func()
			req_limit_headers = list( res.headers.get(k)
				for k in ['X-RateLimit-Remaining', 'X-RateLimit-Reset'] )
			if any(req_limit_headers):
				warn, req_limit_vals = False, list(req_limit_defaults)
				for n, v in enumerate(req_limit_headers):
					try: req_limit_vals[n] = float(v)
					except ValueError as err: warn = False
				if warn:
					self.log.warning( 'Failed to parse rate-limit http'
						' header value(s), assuming default(s): {!r} / {!r}', *req_limit_headers )
				req_limit, req_limit_ts = self.rate_limits[route] = req_limit_vals
			if res.status == 429:
				m = await res.json()
				delay = m.get('retry_after')
				if delay:
					self.log.debug( 'Rate-limiting request on route'
							' {!r}: explicit-retry-after, delay={:,.1f}s, global={}, msg={!r}',
						route, delay, m.get('global'), m.get('message') )
					await asyncio.sleep(float(delay) + self.conf.discord_http_delay_padding)
					continue
				elif req_limit <= 0 and req_limit_ts and req_limit_ts > time.time(): continue
				else:
					raise DiscordSessionError(
						'Failed to get API rate-limiting retry delay for http-429 error' )
			break
		return res

	async def req_auth_token(self):
		if isinstance(self.auth_token, asyncio.Event): await self.auth_token
		elif not self.auth_token:
			if self.auth_token_manual:
				raise DiscordAbort( 'Authentication token is set'
					' to be configured manually, but is not specified' )
			self.auth_token = asyncio.Event()
			email, pw = (self.get_auth(k) for k in ['email', 'password'])
			res = await self.req( 'auth/login', m='post',
				auth=False, json=dict(email=email, password=pw) )
			if res.get('mfa'):
				raise DiscordAbort( 'Multi-factor auth'
					' requirement detected, but is not supported by rdircd' )
			self.conf.set('auth_token', res['token'])
			self.conf.update_file_section('auth', 'token')
			self.auth_token.set()
			self.auth_token = self.get_auth('token')
		return self.auth_token

	async def req( self, url, m='get',
			route=None, auth=True, raw=False, **kws ):
		if not re.search(r'^https?:', url): url = urllib.parse.urljoin(self.api_url, url.lstrip('/'))
		if route is None: route = url
		kws.setdefault('headers', dict()).setdefault(
			'User-Agent', self.conf.discord_api_user_agent )
		for att in 'normal', 'token_refresh':
			if auth:
				token = await self.req_auth_token()
				kws.setdefault('headers', dict()).update(Authorization=token)
			req_func = ft.partial(self.http.request, m, url, **kws)
			self.log_http.debug(' >> {} {}', m, url, extra=(' >>', f'{m} {url}'))
			res = await self.rate_limit_wrapper(route, req_func)
			if not auth: break
			if res.status == 401:
				res.release()
				if att != 'normal': raise DiscordSessionError('Auth failed')
			break
		if res.status >= 400:
			body = await res.text()
			raise DiscordHTTPError(f'[{res.status}] {res.reason} - {body}')
		if not raw:
			res_raw = res
			try: res = await res.json()
			except aiohttp.ContentTypeError:
				body = await res.text()
				raise DiscordHTTPError(
					f'[{res.status}] non-JSON data ({res.content_type}) - {body}' ) from None
			finally: res_raw.release()
		res_repr = str(res)
		if '\n' in res_repr: res_repr = (res_repr.strip() + ' ').splitlines()[0]
		self.log_http.debug('<<  {}', self._repr(res_repr), extra=('<< ', res_repr))
		return res


	### Gateway Websocket wrappers

	async def ws_connect_loop(self):
		opts = adict((k, parse_duration(
			self.conf.get(f'discord_ws_reconnect_{k}') )) for k in ['min', 'max'] )
		opts.factor = self.conf.discord_ws_reconnect_factor
		reconn_warn_tb = token_bucket(self.conf.discord_ws_reconnect_warn)
		interval, loop = opts.min, asyncio.get_running_loop()
		self.log.debug('Starting ws_connect_loop...')
		while self.ws_enabled:
			if next(reconn_warn_tb):
				self.log.warning( 'Reconnecting to discord faster than {},'
						' can be persistent problem, see info/debug/protocol logs for details',
					self.conf.discord_ws_reconnect_warn )
				# Reset tbf to avoid re-issuing warning on every subsequent reconnect
				reconn_warn_tb = token_bucket(self.conf.discord_ws_reconnect_warn)
			try: await self.ws_connect()
			except DiscordSessionError as err:
				self.log.info('Connection failure, retrying in {:.1f}s: {}', interval, err)
				await asyncio.sleep(interval)
				interval = min(opts.max, interval * opts.factor)
				continue
			except Exception as err:
				self.log.exception( 'Unexpected error,'
					' stopping reconnection loop: {}', err_fmt(err) )
				await self.ws_close()
				break
			ts0 = loop.time()
			await self.ws_closed.wait()
			if not self.ws_enabled: break
			ts_diff = loop.time() - ts0
			if ts_diff > interval:
				interval = opts.min
				self.log.info('Disconnected, reconnecting immediately')
			else:
				interval = min(opts.max, interval * opts.factor)
				delay = interval - ts_diff
				self.log.info( 'Disconnected too quickly'
					' ({:.1f}s), reconnecting in {:.1f}s', ts_diff, delay )
				await asyncio.sleep(delay)
		self.log.debug('ws_connect_loop finished')

	async def ws_connect(self):
		if self.ws_ctx: return
		if not self.ws_closed_clean.is_set():
			self.log.warning('BUG: ws_connect issued before old websocket is closed')
			await self.ws_closed_clean.wait()
		self.state('connecting.init')
		self.ws_ctx = ctx = cl.AsyncExitStack()
		self.ws, self.ws_tasks = None, StacklessContext(self.log)
		self.ws_handlers, self.ws_nonces = dict(), dict()
		ctx.push_async_callback(self.ws_close)
		self.ws_closed.clear()
		for cache in True, False:
			if cache:
				if not self.conf.discord_gateway: continue
				self.state('connecting.ws.cached')
			else:
				self.state('connecting.ws.get-url')
				try: self.conf.discord_gateway = (await self.req('gateway', auth=False))['url']
				except aiohttp.ClientError as err:
					self.state('connecting.ws.error')
					self.log.info('Failed to fetch discord gateway URL: {}', err_fmt(err))
					continue # ws_connect will fail
				self.conf.update_file_section('discord', 'gateway')
			parts = adict(urllib.parse.urlsplit(self.conf.discord_gateway)._asdict())
			query = urllib.parse.parse_qs(parts.query)
			query.update(v=str(self.api_ver), encoding='json', compress='zlib-stream')
			parts.query = urllib.parse.urlencode(query)
			ws_url = urllib.parse.urlunsplit(tuple(parts.values()))
			self.log_ws.debug('--- -conn- {}', ws_url, extra=('---', f'conn {ws_url}'))
			self.state('connecting.ws')
			try:
				self.ws = await ctx.enter_async_context(self.http.ws_connect(
					ws_url, heartbeat=self.conf.discord_ws_heartbeat,
					headers={'User-Agent': self.conf.discord_api_user_agent},
					timeout=self.conf.discord_ws_timeout, max_msg_size=20 * 2**20 ))
			except aiohttp.ClientError as err:
				err_str = err_fmt(err)
				self.log_ws.debug('--- -conn-fail- {}', err_str, extra=('---', f'conn-fail {err_str}'))
				self.state('connecting.ws.error')
				self.log.info('Gateway connection error: {}', err_str)
				if cache: continue # try fetching new gw url
			else: break
		else: self.ws = None
		if self.ws_closed.is_set():
			self.ws_closed.clear() # to have it do cleanup again
			await self.ws_close()
			raise DiscordSessionError('Close-command issued while connecting')
		if not self.ws:
			self.state('connecting.ws.fail')
			await self.ws_close()
			raise DiscordSessionError('Failed to connect to discord')
		self.state('connected')
		self.ws_add_handler(self.c.dispatch, self.op_track_seq)
		self.ws_add_handler(self.c.reconnect, self.op_reconnect)
		self.ws_add_handler(self.c.hello, self.op_hello)
		self.ws_add_handler(self.c.invalid_session, self.op_invalid_session_retry)
		self.ws_tasks.add(self.ws_poller())

	_ws_handler = cs.namedtuple('ws_handler', 'op t func')
	def ws_add_handler(self, op=None, func=None, t=None, replace=False, remove=False):
		if replace or remove:
			for k, wsh in list(self.ws_handlers.items()):
				if wsh.op == op and wsh.t == t: del self.ws_handlers[k]
			if remove: return
		if not func: raise ValueError(func)
		wsh = self._ws_handler(op, t, func)
		self.ws_handlers[wsh] = wsh

	async def ws_poller(self):
		try: await self.ws_poller_loop()
		except Exception as err:
			self.log.exception('Unhandled ws handler failure, aborting: {}', err_fmt(err))
		await self.ws_close()

	async def ws_poller_loop(self):
		# {op=0**, s=**42, d={...}, t=**'GATEWAY_EVENT_NAME'}
		# {op=...[, d={...}]}
		inflator, buff, buff_end = zlib.decompressobj(), bytearray(), b'\x00\x00\xff\xff'
		async for msg in self.ws:
			msg_type, msg_data = msg.type, getattr(msg, 'data', '')
			if msg_type == aiohttp.WSMsgType.binary:
				buff.extend(msg_data or b'')
				if msg_data[-4:] != buff_end: continue # partial data
				msg_data = inflator.decompress(buff).decode()
				msg_type = aiohttp.WSMsgType.text
				buff.clear()
			if msg_type == aiohttp.WSMsgType.text:
				self.log_ws.debug( '<<  {} {}', msg_type.name.lower(),
					self._repr(msg_data), extra=('<< ', f'{msg_type} {msg_data}') )
				msg_data, hs_discard, handled = adict(json.loads(msg_data)), set(), False
				if self.conf.ws_dump_filter and self.conf.ws_dump_file:
					chk = self.conf.ws_dump_filter
					if ( chk.get('op') == msg_data.get('op')
							and chk.get('t') == msg_data.get('t') ):
						with open(self.conf.ws_dump_file, 'w') as dst: dst.write(msg_data)
				for k, h in list(self.ws_handlers.items()):
					if h.op is not None and msg_data.get('op') != h.op: continue
					if h.t is not None and (msg_data.get('t') or '').lower() != h.t: continue
					handled = True
					status = await aio_await_wrap(h.func(msg_data))
					if status is self.c.oneshot: hs_discard.add(k)
				for k in hs_discard: self.ws_handlers.pop(k, None)
				if not handled:
					err, msg_repr = 'unhandled-text', self._repr(msg_data)
					self.log_ws.debug( 'xxx {} {}', err,
						msg_repr, extra=('xxx', f'{err} {msg_data}') )
					self.log.debug('Unhandled ws event: {}', msg_repr)
			elif msg_type == aiohttp.WSMsgType.closed: break
			elif msg_type == aiohttp.WSMsgType.error:
				self.log_ws.debug('err {}', msg, extra=('err', msg))
				self.log.error('ws protocol error, aborting: {}', msg)
				break
			else: self.log.warning('Unhandled ws msg type {}, ignoring: {}', msg.type, msg)

	async def ws_send_task(self, msg_data):
		try: await self.ws.send_str(msg_data)
		except ConnectionError as err: # not handled by aiohttp in some cases
			self.log.info('Conn error when trying to send last protocol data: {}', err_fmt(err))
			self.state('connection.fail')
			self.ws_close_later()

	def ws_send(self, op, d):
		msg_data = json.dumps(dict(op=op, d=d))
		self.log_ws.debug( ' >> text {}',
			self._repr(msg_data), extra=(' >>', f'text {msg_data}') )
		self.tasks.add(self.ws_send_task(msg_data))

	def ws_close_later(self):
		'Wrapper to schedule ws_close() from one of ws_tasks or synchronously.'
		# Idea here is just to avoid ws_close_task() cancelling itself
		self.tasks.add(self.ws_close())

	def ws_close(self):
		# Makes sure that only one ws_close_task()
		#  is scheduled at a time, and only if needed
		if ( self.ws_closed.is_set()
			or not self.ws_closed_clean.is_set() ): return asyncio.sleep(0)
		self.ws_closed_clean.clear()
		return self.ws_close_task()

	async def ws_close_task(self):
		try:
			if self.ws_closed.is_set():
				return self.log.warning('BUG: ws_close with websocket already closed')
			self.log_ws.debug('--- -close-', extra=('---', 'close'))
			self.state('closing')
			if self.ws_nonces:
				for fut in self.ws_nonces.values(): fut.cancel()
			if self.ws_tasks: await self.ws_tasks.close()
			if self.ws: await self.ws.close()
			self.ws_ctx = self.ws = self.ws_tasks = self.ws_handlers = self.ws_nonces = None
			self.state('disconnected')
			self.ws_closed.set()
		finally: self.ws_closed_clean.set()


	### Gateway Websocket request wrappers (rare)

	async def ws_req_users_query(self, gid, query, limit):
		nonce = self.discord.flake_build(time.time())
		fut = self.ws_nonces[nonce] = asyncio.Future()
		self.ws_send( self.c.request_guild_members,
			dict(nonce=nonce, guild_id=[gid], presences=False, limit=limit, query=query) )
		try: return await fut
		finally: del self.ws_nonces[nonce]

	def ws_req_thread_list_sync(self):
		for gid, gg in self.st.guilds.items():
			if gid == 1: continue # "me" pseudo-guild
			chan_req = list( (cc.id, [[0, 99]])
				for cc in gg.chans.values() if cc.t == self.c_chan_type.text )
			if not chan_req: continue
			# It doesn't seem to matter what channels= are sent in request_sync_chan -
			#   all threads are returned regardless, along with GUILD_MEMBER_LIST_UPDATE and such
			self.ws_send( self.c.request_sync_chan,
				dict(guild_id=gid, threads=True, channels=dict([chan_req[0]])) )

	### Gateway Websocket event handlers

	def op_track_seq(self, m): self.st.seq = m.s

	def op_reconnect(self, m):
		self.log.info('Received reconnect event - closing connection')
		self.ws_close_later()

	async def op_hello(self, m):
		self.state('hello')
		self.st.hb_interval = m.d.heartbeat_interval / 1e3
		await self.op_hello_auth()
		return self.c.oneshot

	async def op_hello_auth(self):
		self.state('hello.auth.token')
		token = await self.req_auth_token()
		if not self.st.get('session_id'):
			self.state('hello.auth.identify')
			self.ws_add_handler( self.c.dispatch,
				t='ready', func=self.op_ready, replace=True )
			# Note: sending API intents seem to strip "contents" from other people's messages!
			self.ws_send(self.c.identify, dict(
				properties={'$os': 'linux', '$browser': 'rdircd', '$device': 'rdircd'},
				token=token, compress=False, large_threshold=250 ))
		else:
			self.state('hello.auth.resume')
			self.ws_add_handler( self.c.dispatch,
				t='resumed', func=self.op_ready, replace=True )
			self.ws_send(self.c.resume, dict(
				token=token, session_id=self.st.session_id, seq=self.st.get('seq') ))

	async def op_invalid_session_retry(self, m):
		# "expected to wait a random amount of time -
		#  - between 1 and 5 seconds - then send a fresh Opcode 2 Identify"
		self.state('session.error.delay')
		delay = asyncio.create_task(asyncio.sleep(1 + random.random() * 4))
		if not m.get('d') and self.st.get('session_id'):
			self.log.info('Session+auth rejected - trying new session')
			self.st.session_id = self.st.seq = None
			await delay
		else:
			if self.auth_token_manual:
				self.log.info( 'Auth rejected, but auth token'
					' is set to be manual, so just retrying once more' )
			else:
				self.log.info('Auth rejected - updating auth token')
				self.auth_token = None
				token = await self.req_auth_token()
			await delay
			self.ws_add_handler( self.c.invalid_session,
				self.op_invalid_session_fail, replace=True )
		self.state('session.error')
		await self.op_hello_auth()

	def op_invalid_session_fail(self, m):
		if self.conf.discord_ws_reconnect_on_auth_fail:
			self.state('session.auth-fail-reconnect')
		else:
			self.log.warning('Session/auth rejected unexpectedly - disabling connection')
			self.state('session.fail')
			self.ws_enabled = False
		self.ws_close_later()

	def op_invalid_session_event(self, m):
		self.log.warning('Unexpected "invalid session" event - reconnecting')
		self.state('session.fail')
		self.ws_close_later()

	def op_ready(self, m):
		md = m.get('d')
		if md and md.get('session_id'):
			self.st.update(
				session_id=md.session_id,
				user_id=md.user.id,
				user_name=md.user.username,
				user_n=md.user.discriminator )
			self.op_ev_guilds(md.get('guilds'), sync=True)
			self.op_ev_chans(self.st.me.id, md.get('private_channels'), sync=True)
			self.ws_req_thread_list_sync()
		self.state('ready')
		self.ws_add_handler(self.c.dispatch, func=self.op_ev)
		self.ws_add_handler( self.c.invalid_session,
			self.op_invalid_session_event, replace=True )
		self.ws_tasks.add(self.op_heartbeat_task(self.st.hb_interval))
		return self.c.oneshot

	async def op_heartbeat_task(self, interval):
		loop = asyncio.get_running_loop()
		self.st.hb_ts_ack = hb_ts = loop.time() + interval
		self.ws_add_handler(self.c.heartbeat_ack, self.op_heartbeat_ack)
		while not self.ws_closed.is_set():
			self.ws_send(self.c.heartbeat, self.st.get('seq'))
			ts = loop.time()
			if self.st.hb_ts_ack < ts - interval*2:
				self.log.info('Missing heartbeat ack, reconnecting')
				self.state('heartbeat.fail')
				return self.ws_close_later()
			while hb_ts <= ts: hb_ts += interval
			delay = hb_ts - ts
			await asyncio.sleep(delay)

	def op_heartbeat_ack(self, m):
		self.st.hb_ts_ack = asyncio.get_running_loop().time()

	def op_ev(self, m):
		mt = (m.get('t') or '').lower()
		try: o, act = mt.rsplit('_', 1)
		except ValueError: o = act = None
		try: gid = m.d.guild_id
		except: gid = None

		# Events with some handling needed
		if o == 'guild':
			if act in ['create', 'update']: return self.op_ev_guilds(m.d)
			elif act == 'delete': return self.op_ev_delete(gid)
		elif mt.startswith('guild_member_'):
			act = mt[13:]
			if act == 'list_update': return self.op_ev_member_ops(m.d)
			elif act in ['add', 'update']: return self.op_ev_member(m.d)
			elif act == 'remove': return self.op_ev_member(m.d, delete=True)
		elif mt == 'guild_members_chunk': return self.op_ev_member_chunk(m.d)
		elif mt == 'thread_list_sync': return self.op_ev_thread_list(m.d)
		elif o == 'guild_ban':
			if act in ['add', 'remove']: return self.op_ev_ban(m.d, act)
		elif o == 'guild_scheduled_event': return self.op_ev_sched(m.d, act)
		elif o in ['channel', 'thread']:
			if act in ['create', 'update']: return self.op_ev_chans(gid or 1, m.d)
			elif act == 'delete': return self.op_ev_delete(gid or 1, chan=m.d.id)
		elif o == 'channel_recipient': return self.op_ev_recipient(m.d, act)
		elif o == 'message':
			if act in ['create', 'update', 'delete']: return self.op_msg(m.d, act)
			elif act == 'ack': return # reading private chats from browser
		elif o == 'relationship': return self.op_ev_rel(m.d, act)
		elif mt == 'message_delete_bulk': # can maybe shorten notice-spam here somehow
			for msg_id in m.d.ids: self.op_msg(adict(id=msg_id, **m.d), 'delete')
			return
		elif mt == 'gift_code_update': return self.op_gift_code(m.d)
		elif mt.startswith('message_reaction_'): return self.op_react(m.d, mt[17:])

		# Known-ignored events
		elif o in [ 'typing', 'integration', 'channel_pins', 'webhooks',
			'presence', 'presences', 'thread_member', 'thread_members',
			'guild_emojis', 'guild_integrations', 'guild_role', 'stage_instance' ]: return
		elif re.search( r'^(voice|guild_scheduled_event'
			r'|(guild_)?application_command)_', mt ): return
		elif mt in [ 'sessions_replace', 'user_guild_settings_update',
			'user_note_update', 'user_settings_update', 'invite_create' ]: return

		# Known stuff must be explicitly handled above to not generate "Unhandled event"
		self.log.warning('Unhandled event: {}', self._repr(m))

	def op_ev_thread_list(self, d):
		self.op_ev_chans(d.guild_id, d.threads, sync=False)

	def op_ev_member_chunk(self, d):
		user_map = dict()
		for m in d.get('members', list()):
			uid, name = self.op_ev_member(m, d.guild_id)
			user_map[uid] = name
		nonce = d.get('nonce')
		if nonce: self.ws_nonces[nonce].set_result(user_map)

	def op_ev_member_ops(self, d):
		for o in d.get('ops', list()):
			for item in o.get('items') or list():
				m = item.get('member', dict())
				if m: self.op_ev_member(m, d.guild_id, delete=o.op=='DELETE')

	def op_ev_member(self, m, gid=None, delete=False):
		if not gid: gid = m.guild_id
		self.discord.cmd_user_cache(
			gid, m.user.id, m.user.username if not delete else None )
		return m.user.id, m.user.username # used in queries

	def op_ev_delete(self, gid=None, chan=...):
		gg = self.st.guilds.get(gid)
		if not gg: return
		if chan is not ...: gg.chans.pop(chan, None)
		else: self.st.guilds.pop(gid, None)

	def op_ev_guilds(self, guilds, sync=False):
		gs_new, gs_chans = {1: self.st.me}, dict()
		for g in force_list(guilds):
			if g.get('unavailable'): continue # can be sent in "ready" event
			if g.id == self.st.me.id or g.name == self.st.me.name:
				self.log.error('Skipping guild due to id/name conflict with "me" guild: {}', g)
				continue
			if g.id not in self.st.guilds:
				self.log.debug('New guild: gid={} name={!r}', g.id, g.name)
			gg = gs_new.setdefault( g.id,
				self.st.guilds.get(g.id, adict(id=g.id, chans=dict())) )
			ts_joined = g.get('joined_at') or 0
			if ts_joined: ts_joined = parse_iso8601(ts_joined)
			gg.update(
				name=g.name, ts_joined=ts_joined,
				roles=dict((r.id, r) for r in g.get('roles', list())) )
			if 'channels' in g: gs_chans[g.id, 'c'] = g.channels # missing in guild_update evs
			if 'threads' in g: gs_chans[g.id, 't'] = g.threads # only "joined" ones are listed here!
		dict_update(self.st.guilds, gs_new, sync=sync)
		for (gid, sk), chans in sorted(gs_chans.items()):
			self.op_ev_chans(gid, chans, sync=sk == 'c')

	def op_ev_chans(self, gid, chans, sync=None):
		def _gg_prefix():
			try:
				return ( self.discord.bridge.cache.gid_prefix.get(gg.id)
					or self.discord.bridge.uid('guild', gg.id, kh=gg.get('kh')) )
			except: return '???' # digs a bit too far to get that debug info
		gg = self.st.guilds.get(gid)
		if not gg: return
		cs, ct = dict(), self.c_chan_type
		chan_name_changes, new_threads = list(), list() # for disambiguation checks/notifications

		for c in force_list(chans):
			name, topic = c.get('name'), c.get('topic')
			if c.type in [ct.voice, ct.group, ct.store, ct.stage]: continue
			try: cc_type = ct(c.type)
			except ValueError:
				self.log.error( 'BUG - ignoring unknown channel'
						' type={}: guild={!r} (id={} prefix={}) name={!r} topic={!r} id={}',
					c.type, gg.name, gg.id, _gg_prefix(), name, topic, c.id )
				continue

			if c.type in [ct.thread, ct.thread_news, ct.thread_private]:
				cc_parent = gg.chans.get(c.parent_id) or cs.get(c.parent_id)
				if not cc_parent:
					self.log.error( 'BUG - ignoring thread sub-channel with'
							' unknown parent-chan={}: guild={!r} (id={} prefix={}) name={!r} id={}',
						c.parent_id, gg.name, gg.id, _gg_prefix(), name, c.id )
					continue
				c_tid = self.conf.discord_thread_id_prefix
				c_tid += str_hash( c.id, 4,
					strip=(c_tid.lower() + c_tid.upper()) if len(c_tid) == 1 else '' ).lower()
				topic, name = f'[thread {c_tid}] {name}', name[:self.conf.irc_thread_chan_name_len]
				if name: name = f'.{name}'
				name = f'{cc_parent.name}.{c_tid}{name}'
			else: c_tid = None

			cc = cs.setdefault( c.id,
				gg.chans.get(c.id, adict(users=adict(), threads=adict())) )
			cc.name_raw = name
			name_old, name_old_base = cc.get('name'), cc.get('name_base')
			if c_tid:
				cc.tid, cc.parent, cc_parent.threads[c_tid] = c_tid, cc_parent, cc
				if not name_old: new_threads.append(cc)
			elif c.type in [ct.private, ct.private_group]:
				ts, users= time.time(), c.get('recipients') or list()
				for u in users: self.discord.cmd_user_cache(gid, u.id, u.username)
				dict_update( cc.users,
					( (u.username, adict(name=u.username, ts=ts))
						for u in (c.get('recipients') or list()) ), sync=True )
				user_names = list(u.name for u in cc.users.values())
				if len(user_names) >= self.conf.irc_private_chat_min_others_to_use_id_name:
					# Hash-name is not descriptive, but should stay the same
					# Caveat: channel names are case-insensitive, even if hash is not
					name = f'chat.{str_hash(c.id, 10)}'
				else: name = f'chat.{self.op_ev_chans_priv_name(user_names)}'
				if not topic: topic = f'private chat [{len(user_names)}] - ' + ', '.join(user_names)

			alias = self.conf.aliases.get(('chan', f'@{c.id}'))
			if not alias:
				alias = self.conf.aliases.get(
					('chan', self.discord.bridge.irc_name(name).lower()) )
			if alias:
				self.log.debug('Using alias-name for channel/thread: {} -> {}', name, alias)
				name = alias

			cc.update(
				id=c.id, gid=gg.id, did=f'#{gg.id}-{c.id}',
				name_base=name, name=name, t=cc_type,
				pos=c.get('position', -1)+1, topic=topic, nsfw=c.get('nsfw'),
				last_msg=c.get('last_message_id'), last_pin=c.get('last_pin_timestamp') )

			if name_old and name_old != name_old_base:
				# For already-disambiguated chans, all name_old_base channels might need update
				# Might not affect cc if name was updated, but will change/remove suffix on others
				chan_name_changes.append((cc, name_old_base, name_old))
			if name != name_old: chan_name_changes.append((cc, name, name_old)) # new chans too

		# Process channel name changes, if any, send notifications
		# Disambiguation here doesn't affect threads, as they have unique ids in them already
		cs_affected = dict() # other channels affected by disambiguation
		for cc, name, name_old in chan_name_changes:
			for cca, cca_name_old in self.op_ev_chans_update_disambiguation(cs, name):
				if cca.id != cc.id: cs_affected[cca.id] = cca, cca_name_old
		new_renames = list()
		for cc, name, name_old in chan_name_changes:
			if not name_old:
				if not cc.get('tid'): # logged separately below
					self.log.debug( 'New channel [id={} gid={}]:'
						' {!r} ({!r})', cc.id, gg.id, cc.name, cc.topic or '' )
			elif cc.name != name_old: new_renames.append((cc, name_old))
			cs_affected.pop(cc.id, None)
		for cc, name_old in cs_affected.values(): new_renames.append((cc, name_old))

		dict_update(gg.chans, cs, sync=sync)
		self.discord.cmd_chan_map_update()

		if sync is None: # otherwise they'll be mentioned on every (re-)connect
			# Should be needed if msgs from these to parent chan are disabled
			for cc in new_threads:
				self.log.debug( 'New thread-channel'
					' [id={} gid={}]: {!r} ({!r})', cc.id, gg.id, cc.name, cc.topic or '' )
				self.discord.cmd_chan_thread(cc)
		for cc, name_old in new_renames: self.discord.cmd_chan_rename(cc, name_old)

	def op_ev_chans_update_disambiguation(self, cs, name):
		'Renames same-name channels to "chan.1" "chan.2" etc, yielding (cc, name_old) tuples'
		# Must always yield same renames for same set(s) of channel names
		irc_name, irc_chans = self.discord.bridge.irc_name(name).lower(), list()
		for cc in cs.values():
			if self.discord.bridge.irc_name(cc.name_base).lower() != irc_name: continue
			irc_chans.append(cc)
		if not irc_chans: return # can happen if old matching channels were removed
		if len(irc_chans) == 1: # remove unnecessary disambiguation
			cc = irc_chans[0]
			if cc.name_base != cc.name:
				yield cc, cc.name
				cc.name = cc.name_base
			return
		for n, cc in enumerate(sorted(irc_chans, key=op.itemgetter('did')), 1):
			name = f'{cc.name_base}.{n}'
			if name != cc.name: yield cc, cc.name
			cc.name = name

	def op_ev_chans_priv_name(self, user_names):
		'Makes channel name of limited length from possibly-truncated usernames'
		n = max_len_chan = self.conf.irc_private_chat_name_len
		min_len_user = self.conf.irc_private_chat_name_user_min_len
		while True:
			name = '+'.join(sorted(name.replace('+', '')[:n] for name in user_names))
			if n <= min_len_user or len(name) <= max_len_chan: return name[:max_len_chan]
			n -= 1

	def op_ev_recipient(self, m, act):
		# Sometimes this gets sent instead of c_msg_type.recipient_add, didn't check why
		# No guild_id passed here (always "me"), only user + channel_id
		cc, u = self.st.guilds[1].chans.get(m.channel_id), m.get('user', dict())
		if u: self.discord.cmd_user_cache(1, u.id, u.username)
		self.discord.cmd_msg_recv(cc, u.get('username'), f'--- recipient {act.lower()}')

	def op_ev_ban(self, m, act):
		name = self.st.guilds.get(m.guild_id), m.get('user', dict())
		name = name.get('username') or f'@{name.get("id", "???")}'
		self.discord.cmd_guild_event(m.guild_id, f'guild user ban: {act} {name}')

	def op_ev_rel(self, m, act):
		t, name = m.get('type'), m.get('user')
		try: t = self.c_rel_type(t).name
		except ValueError: t = f'unknown[{t}]'
		if name: name = name.username
		uid, name = m.get('id', '?'), '' if not name else f' name={name}'
		self.discord.cmd_guild_event(1, f'relationship: [uid={uid}{name}] {act} {t}')

	def op_ev_sched(self, m, act):
		ev_st, ev_hash = m.get('status'), str_hash(m.id, 4)
		ts0, ts1 = (m.get(f'scheduled_{k}_time') for k in ['start', 'end'])
		ev_info = [m.get('name')]
		if ts0:
			ts0, ts1 = ((v and parse_iso8601(v)) for v in [ts0, ts1])
			ts_ext = f'{ts_iso8601(ts0, human=True)}'
			if ts1: ts_ext += f' - {ts_iso8601(ts1, human=True, strip_date=ts0)}'
			ts_ext += f' [{repr_duration(ts0, time.time())}'
			if ts1: ts_ext += f', lasts {repr_duration(ts1, ts0, ext=False)}'
			ev_info.append(ts_ext + ']')
		ev_info.extend([m.get('description', ''), ' '.join(
			f'{k}=[ {v} ]' for k,v in (m.get('entity_metadata') or dict()).items() )])
		ev_info = ' :: '.join(filter(None, ev_info))
		if not ev_info: # dunno how to translate it, so print a kind of debug info
			ev_info = f'type={m.get("entity_type", "?")} status={m.get("status", "?")}'
		if act == 'update': act = f' {act}' + (' - started' if ev_st == 2 else '')
		else: act = f' {act}' if act != 'create' else ''
		self.discord.cmd_guild_event( m.guild_id,
			f'scheduled event <{ev_hash}>{act}: {ev_info}' )

	def op_msg(self, m, act, cc=None, tid_prefix=''):
		gg = self.st.guilds.get(m.get('guild_id', 1))
		if not cc:
			if gg: cc = gg.chans.get(m.channel_id)
			if not cc:
				return self.log.warning( 'Dropped msg event with unknown guild/channel'
					' id: msg_id={} guild_id={} channel_id={}', m.id, m.get('guild_id'), m.channel_id )
		if cc.get('tid') and self.conf.discord_thread_msgs_in_parent_chan:
			prefix = not self.conf.discord_thread_msgs_in_parent_chan_full_prefix
			prefix = cc.tid if prefix else self.discord.irc_chan_name(cc)
			self.op_msg(m, act, cc=cc.parent, tid_prefix=f'{tid_prefix}{prefix} :: ')
		if act == 'delete':
			msg_ts = ts_iso8601(self.discord.flake_parse(m.id), human=True)
			return self.discord.cmd_msg_recv( cc,
				None, f'--- message was deleted: {msg_ts} [{m.id}]' )
		flake, author = None, m.get('author')
		if not author:
			if ( act == 'update'
					and not set(m.keys()).difference('id flags embeds channel_id guild_id'.split()) ):
				return # type=rich/image updates, latter with same exact links - not useful
			self.log.warning('Unhandled no-author msg type: {} [{}]', self._repr(m), act)
			return
		else: self.discord.cmd_user_cache(gg.id, author.id, author.username)
		line, tags = self.op_msg_parse(m, gg)
		if not line: return # joins/parts/pins and such
		if act == 'update': tags['_prefix'] = tags.get('_prefix', '') + self.conf.irc_prefix_edit
		else:
			flake, ref = m.id, m.get('referenced_message')
			if self.conf.irc_inline_reply_quote_len > 0 and ref:
				ref_user = ref.get('author', dict()).get('username')
				ref_user = f'<{ref_user}>' if ref_user else ''
				ref_line, ref_tags = self.op_msg_parse(ref, gg)
				ref = str_repr(ref_line, self.conf.irc_inline_reply_quote_len)
				if ref_user and ref:
					line = f'-- re:{ref_user} {ref}\n{line.strip()}'
					tags.update((k,v) for k,v in ref_tags.items() if not k.startswith('_'))
		if tid_prefix: tags['_prefix'] = tags.get('_prefix', '') + tid_prefix
		skip_mirrored_msg_in_monitor = (
			tid_prefix and not self.conf.discord_thread_msgs_in_parent_chan_monitor )
		self.discord.cmd_msg_recv(
			cc, author.username, line.strip(), tags, flake=flake,
			nonce=m.get('nonce'), skip_monitor=skip_mirrored_msg_in_monitor )

	def op_msg_parse(self, m, gg):
		# Must produce non-empty message for any relevant msg type
		# Most message types are protocol notifications that have their "content" discarded
		# Also used for parsing history query responses, not just events
		tags, mt, mt_nx, line = dict(), m.get('type', ''), False, (m.get('content') or '').strip()
		line, mtc = line.replace('\u200b', ''), self.c_msg_type # unicode zero-width-space junk
		try:
			if not mt and m.get('author', dict()).get('bot'):
				if m.get('embeds'): mt = mtc.bot_embeds
				# Otherwise empty message_update bumps and/or something webhook-related?
				# Msgs from bots updating their embeds can be filtered-out via "flags = loading"
			else:
				mt = mtc(int(mt))
				if mt not in [mtc.default, mtc.reply]: line = ''
		except ValueError: # new unknown msg type - check how to handle
			self.log.warning('Unhandled msg type [{!r}]: {}', mt, self._repr(m))
			if line: tags['_prefix'] = f'[msg-type={mt!r}] '
			mt_nx = True
		if line: tags.update(self.op_msg_parse_tags(line, m, gg.chans, gg.get('roles')))

		if mt == mtc.bot_embeds:
			for n, em in enumerate(m.embeds):
				pre = self.conf.irc_prefix_embed.format(tuple_hash((m.id, n), 3))
				if em.get('author'):
					info = ' '.join(em.author.get(k, '') for k in ['name', 'url']).strip()
					if info: line += f'\n{pre}[author] {info}'
				if em.get('title'): line += f'\n{pre}-- {em.title.strip()} --'
				if em.get('description'):
					info = (dl.strip() for dl in em.description.splitlines())
					for info in filter(None, info): line += f'\n{pre}{info}'

		for att in m.get('attachments') or list():
			url = att.get('url')
			if not url:
				self.log.warning('Unhandled msg attachment type: {}', self._repr(att))
				continue
			line += f'\n{self.conf.irc_prefix_attachment}{url}'
		for stk in m.get('stickers') or m.get('sticker_items') or list():
			name, desc = stk.get('name'), stk.get('description')
			line += f'\n{self.conf.irc_prefix_sticker}{name}'
			if desc: line += f' ({desc})'
		uis = m.get('components')
		if uis:
			def _tags(uis, types=dict(enumerate(['row', 'btn', 'menu'], 1))):
				line = list()
				for ui in uis:
					tag = types.get(ui.type, f'ui{ui.type}')
					if ui.get('label'): tag += f' {repr(ui.label)}'
					if ui.get('placeholder'): tag += f' {repr(ui.placeholder)}'
					if ui.get('emoji'): tag += f' :{ui.emoji.name}:'
					if ui.get('url'): tag += f' url={ui.url}'
					if ui.get('options'):
						for opt in ui.options:
							tag += ' ({})'.format(
								opt.get('label', '').replace(' ', '_')
								or f":{opt.get('emoji', dict()).get('name', 'x')}:" )
					line.append(
						f'<{tag}/>' if not ui.get('components') else
						f'<{tag}>' + _tags(ui.components) + f'</{tag}>' )
				return ' '.join(line)
			line += f'\n{self.conf.irc_prefix_uis}' + _tags(m.components)

		if not mt_nx and not line: # represent some non-text/embed events
			if mt == mtc.recipient_add: line = f'[+recipient]'
			elif mt == mtc.recipient_remove: line = f'[-recipient]'
			elif mt == mtc.channel_name_change: line = f'[channel renamed]'
			elif mt == mtc.default:
				self.log.warning( 'Discarded basic text-msg'
					' without contents (processing bug?): {}', self._repr(m) )
		return line.strip(), tags

	def op_msg_parse_tags(self, line, m, chans, roles):
		'Returns string-replacement pairs for discord tags detected within message'
		# https://discord.com/developers/docs/reference#message-formatting
		tags, tags_raw = dict(), list(re.finditer(r'<(@!?|#|a?:[^:]+:|@&|t)(\d+)(:\w)?>', line))
		m_chans = dict((c.id, f'#{c.name}') for c in (m.get('mention_channels') or list()))
		if tags_raw:
			mt, ts_fmts = self.c_msg_tags, self.c_msg_tags_ts_fmts
			users = dict((m.id, m.username) for m in force_list(m.get('mentions')))
			for m in tags_raw:
				k_src, t, k = m.group(0), m.group(1), m.group(2)
				if t in ['@', '@!']: v = mt.user, users.get(k, f'[{k}]')
				elif t == '@&':
					v = mt.role, ( f'[{roles[k].name}]'
						if roles and k in roles else '[role:{}]'.format(str_hash(k, 3)) )
				elif t == '#': v = mt.chan, chans[k].did if k in chans else (m_chans.get(k) or f'#[{k}]')
				elif t.lstrip('a').startswith(':'): v = mt.emo, t.lstrip('a')
				elif t == 't':
					ts, ts_fmt = float(k), ts_fmts.get(m.group(3)) or ts_fmts['f']
					v = mt.ts, '[' + str( ts_fmt(ts) if callable(ts_fmt)
						else dt.datetime.fromtimestamp(ts).strftime(ts_fmt) ) + ']'
				else: v = mt.other, f'{t}{k}'
				tags[k_src] = v
		return tags

	def op_react(self, m, act):
		if self.conf.irc_disable_reactions: return
		cc, gg = None, self.st.guilds.get(m.get('guild_id', 1))
		if gg: cc = gg.chans.get(m.channel_id)
		if not cc: return
		try: # emo_id seem to be only passed if it's not unicode emoji
			emo_id, emo = m.emoji.get('id'), m.emoji.get('name') or ''
			if emo_id and len(emo) != 1: emo = f'[{emo_id}]' if not emo else f':{emo}:'
		except KeyError: emo = ''
		if act == 'remove_all': act, emo = '', f'-all'
		if emo:
			if act == 'add': act, emo = '', f'+{emo}'
			elif act == 'remove': act, emo = '', f'-{emo}'
			else: emo = f' {emo}'
		msg_ts = ts_iso8601(self.discord.flake_parse(m.message_id), human=True)
		try: u = m.member.user
		except: nick = None # notice from nick_sys
		else:
			self.discord.cmd_user_cache(gg.id, u.id, u.username)
			nick = u.username
		self.discord.cmd_msg_recv(cc, nick, f'--- reacts [{msg_ts}]: {act}{emo}')

	def op_gift_code(self, m):
		cc, gg = None, self.st.guilds.get(m.get('guild_id', 1))
		if gg: cc = gg.chans.get(m.channel_id)
		if not cc: return
		self.discord.cmd_msg_recv( cc, None,
			f'--- gift-code: uses={m.uses} sku={m.sku_id} code={m.code}' )



class RDIRCD:

	class c:
		chan_prefix = 'rdircd.'

		chan_control = f'{chan_prefix}control'
		chan_debug = f'{chan_prefix}debug'
		chan_sys_list = [chan_control, chan_debug]

		chan_monitor = f'{chan_prefix}monitor'
		chan_monitor_guild_prefix = f'{chan_prefix}monitor.'

	c_chan_type = enum.Enum('c_chan_type', 'sys mon proxy')

	def __init__(self, conf):
		self.conf, self.init = conf, None
		self.log = get_logger('rdircd.bridge')
		self._repr = ft.partial(str_repr, max_len=self.conf.debug_msg_cut)

	async def __aenter__(self):
		self.server_ver = self.conf.version
		self.server_ts = dt.datetime.utcnow()
		self.server_host = os.uname().nodename
		self.irc_conns, self.irc_conns_max = adict(), 0
		self.irc_auth_tbf = token_bucket(self.conf.irc_auth_tbf)
		self.irc_names_timeout = parse_duration(self.conf.irc_names_timeout)
		self.irc_msg_queue = asyncio.Queue()
		self.nick_sys = 'core'
		self.chans_sys = adict({
			self.c.chan_control: 'rdircd: control channel, type "help" for more info',
			self.c.chan_debug: 'rdircd: debug logging channel, type "help" for more info' })
		self.chans_mon = adict({
			self.c.chan_monitor: 'rdircd: read-only catch-all channel with messages from everywhere' })
		self.tasks = StacklessContext(self.log)
		self.cache = adict( uid=dict(),
			gid_prefix=dict(), did_chan=dict(),
			d2i=irc_name_dict(), i2d=irc_name_dict() )
		self.uid_len, self.uid_seed = (self.conf.get(f'irc_uid_{k}') for k in ['len', 'seed'])
		if not self.uid_seed:
			for k in '/etc/machine-id', '/var/lib/dbus/machine-id':
				try: self.uid_seed = str_hash(pl.Path(k).read_text().strip())
				except OSError: continue
			else: self.uid_seed = f'rdircd.{self.server_host}'
		boot_id = pl.Path('/proc/sys/kernel/random/boot_id').read_text().strip()
		self.uid_start = '.'.join( str_hash(v, c)
			for c, v in zip([3, 3, 6], [self.uid_seed, boot_id, os.urandom(6)]) )
		self.cmd_delay(self.irc_msg_queue_proc)
		self.init = True
		return self

	async def __aexit__(self, *err):
		if self.irc_msg_queue: self.irc_msg_queue.put_nowait(StopIteration)
		if self.tasks: await self.tasks.close()
		self.init = False

	def uid(self, k, v=None, kh=None, hash_len=None):
		if v is None: return self.cache.uid.get(k, (None, None))
		k = k, v
		if k not in self.cache.uid:
			if kh is None:
				kh = str_hash( '\0'.join(map(str, k)),
					hash_len or self.uid_len, self.uid_seed ).lower()
				kh = self.conf.aliases.get((k[0], kh), kh)
			if kh in self.cache.uid:
				# Hash collisions should not happen here - raise uid_len if they do
				raise ValueError(k, kh, self.cache.uid[kh])
			self.cache.uid[k], self.cache.uid[kh] = kh, k
		return self.cache.uid[k]

	async def run(self):
		loop = asyncio.get_running_loop()
		ircd = await loop.create_server(
			IRCProtocol.factory_for_bridge(self),
			self.conf.irc_host, self.conf.irc_port,
			family=self.conf.irc_host_af, start_serving=False )
		self.log.debug('Initializing discord...')
		try:
			async with Discord(self) as discord:
				self.discord = discord
				self.log.debug('Starting ircd...')
				ircd_task = self.tasks.add(ircd.serve_forever())
				if self.conf.discord_auto_connect:
					self.log.debug('Auto-connecting discord...')
					loop.call_soon(discord.connect)
				else: self.log.debug('Note: discord session auto-connect disabled')
				await ircd_task
		except DiscordAbort as err:
			self.log.error('Discord init failure - {}', err_fmt(err))
		self.log.debug('Finished')

	async def run_async(self):
		async with self: await self.run()


	def irc_conn_new(self, irc):
		self.irc_conns[id(irc)] = irc
		self.irc_conns_max = max(self.irc_conns_max, len(self.irc_conns))
	def irc_conn_lost(self, irc): self.irc_conns.pop(id(irc), None)
	def irc_conn_stats(self):
		stats = adict(
			servers=len(self.discord.st.get('guilds', dict())) or 1,
			chans=len(self.cmd_chan_map()),
			total=0, total_max=self.irc_conns_max, unknown=0, auth=0, op=0 )
		for conn in self.irc_conns.values():
			stats.total += 1
			if conn.st.auth: stats.auth += 1
			else: stats.unknown += 1
		return stats
	def irc_conn_names(self):
		for conn in self.irc_conns.values():
			if conn.st.auth: yield conn.st.nick

	def irc_name(self, name):
		# Must be deterministic but ideally not create collisions by stripping too much
		# General idea is to replace all irc-problematic chars by lookalike unicode
		if name not in self.cache.d2i:
			name_irc, sub_chars = '', '°×·„∂¦◄►'
			name_clean = re.sub(rf'[{sub_chars}]', '', name)
			if name_clean != name: name = name_clean + '×' + self.uid('name', name)
			for n, c in enumerate(name):
				if ord(c) < 32: name_irc += f'°{ord(c):02d}'
				elif c == ' ': name_irc += '·'
				elif c == ',': name_irc += '„'
				elif c == ':': name_irc += '¦'
				elif c == '@': name_irc += '∂'
				elif c == '!': name_irc += '¡'
				elif c == '+': name_irc += '×'
				elif c == '<': name_irc += '◄'
				elif c == '>': name_irc += '►'
				else: name_irc += c
			self.cache.d2i[name], self.cache.i2d[name_irc] = name_irc, name
		return self.cache.d2i[name]

	def irc_name_revert(self, nick):
		return self.cache.i2d.get(nick)

	def irc_chan_info(self, name):
		# Note: internal name (cc.name) must always be passed, not lowercased irc one
		if '.' not in name: return
		gid, name = name.split('.', 1)
		(t, gid), chan_name = self.uid(gid), self.irc_name_revert(name)
		if t != 'guild': return
		gg = self.discord.st.get('guilds', dict()).get(gid)
		if not gg: return
		for cc in gg.chans.values():
			if cc.name == chan_name: break
		else: cc = None
		return adict(gg=gg, cc=cc)

	async def irc_topic_cmd(self, conn, name, line=''):
		chan = conn.chan_spec(name)
		notice_cmd = ft.partial( conn.cmd_msg_synth,
			self.nick_sys, chan, notice=True, direct=True )
		cmd = line.split(None, 1)
		if not line.strip() or cmd[0] in ['h', 'help']:
			return notice_cmd('\n'.join([ '--- Topic-commands:',
				'  set {topic...} - set topic, as usual irc /topic command would do.',
				'  info - show some internal guild/channel information, like IDs and such for aliases.',
				'  log [state] - replay history since "state" point (default: last rdircd stop).',
				'    "state" value can be either a number, state-id, relative or iso8601 timestamp.',
				'    Where number indicates last Nth state recorded in the config (0 - current).',
				'    E.g. "log 1" (same as just "log") will replay messages in the channel,',
				'     starting from last ev before last rdircd shutdown (saved under [state] in ini).',
				'    Timestamp examples: 2019-01-05T2:00, 2019-01-08 12:30:00, 2h, 1d 5h 30m, 1mo5d.',
				'    Relative timespan units: y/yr/year, mo/month,',
				'      w/week, d/day, h/hr/hour, m/min/minute, s/sec/second.',
				'  log list - list recorded state ids/timestamps, most recent one last.', '---' ]) )
		try:
			if cmd[0] == 'set':
				raise IRCBridgeSignal('Changing topic is not implemented')
			elif cmd[0] == 'info':
				info = self.irc_chan_info(name)
				if not (info and info.gg and info.cc):
					raise IRCBridgeSignal(f'Not a discord channel: {chan}')
				notice_cmd('--- Protocol information on this guild/channel:')
				notice_cmd('Guild:')
				notice_cmd(f'  id: {info.gg.id}')
				notice_cmd(f'  name: {info.gg.name}')
				notice_cmd(f'  joined-at: {ts_iso8601(info.gg.ts_joined)}')
				notice_cmd('  existing roles:')
				for role in info.gg.roles.values(): notice_cmd(f'    id={role.id} name={role.name}')
				notice_cmd('Channel:')
				notice_cmd(f'  id: {info.cc.id}')
				notice_cmd(f'  name on discord: {info.cc.name_raw or ""}')
				notice_cmd(f'  name/alias without irc encoding: {info.cc.name}')
				notice_cmd(f'  name/alias encoded for irc: {self.irc_name(info.cc.name)}')
				notice_cmd(f'  topic: {info.cc.topic or ""}')
				notice_cmd(f'  type: {info.cc.t.name} [{info.cc.t.value}]')
				notice_cmd(f'--- end of info')
			elif cmd[0] == 'log':
				state = ('1' if len(cmd) == 1 else cmd[1]) if len(cmd) <= 2 else None
				state_list = sorted((v,k) for k,v in self.conf.state.items())
				if state == 'list':
					if not state_list: notice_cmd('No state timestamps recorded yet.')
					else:
						notice_cmd('Recorded state timestamps:')
						for n, (v, k) in enumerate(state_list):
							n = len(state_list) - n - 1
							notice_cmd(f'  [{n}] {k} = {ts_iso8601(v)}')
					return
				ts = None
				if state.isdigit():
					n = -1 - int(state)
					if not self.conf.state_get(self.uid_start): n += 1
					if not n: return
					try: ts, k = state_list[n]
					except IndexError: raise IRCBridgeSignal(f'No state with index {state}')
				elif state in self.conf.state:
					try: ts = self.conf.state[state]
					except KeyError: raise IRCBridgeSignal(f'No state {state!r}')
				else:
					try: ts = parse_iso8601(state)
					except ValueError:
						try: ts = parse_duration(state)
						except ValueError: pass
						else: ts = time.time() - ts
				if ts:
					info = self.irc_chan_info(name)
					if not (info and info.cc): raise IRCBridgeSignal(f'Not a discord channel: {chan}')
					notice_cmd(f'--- Replaying new messages since {ts_iso8601(ts)}')
					msg_list = await self.discord.cmd_history(info.gg, info.cc, ts)
					if not msg_list: return notice_cmd('--- no new messages')
					for m in msg_list:
						line = f'[{ts_iso8601(m.ts, human=True)}] {m.line}'
						self.cmd_msg_discord(info.cc, m.nick, line, m.tags, conn=conn)
					return notice_cmd(f'--- end of replay [{len(msg_list)}]')
				raise IRCBridgeSignal(f'Invalid log-cmd parameters: {line}')
			else: raise IRCBridgeSignal(f'Unrecognized channel-topic cmd: {line}')
		except IRCBridgeSignal as err:
			notice_cmd(f'topic-cmd-error: {err}')
			raise

	def irc_msg(self, conn, chan, line):
		name = conn.chan_name(chan)
		if name in self.chans_sys:
			return self.cmd_chan_sys(name, conn, chan, line)
		if name in self.chans_mon: return
		line = self.irc_msg_translate(line)
		if not line.strip(): return
		if not self.irc_msg_queue:
			conn.cmd_msg_synth( self.nick_sys, chan,
				f'ERR {{irc-msg-queue-failed}}: {line}', notice=True, direct=True )
		else: self.irc_msg_queue.put_nowait(
			adict(conn=conn, chan=chan, name=name, line=line) )

	def irc_msg_translate(self, line):
		# "/me msg" -> "\1ACTION msg\1" - https://tools.ietf.org/id/draft-oakley-irc-ctcp-01.html
		return re.sub(r'^\x01ACTION ?(.*)\x01$', r'_\1_', line)

	async def irc_msg_queue_proc(self):
		try:
			while True:
				m = await self.irc_msg_queue.get()
				if m is StopIteration: break
				info = self.irc_chan_info(m.name)
				try:
					if not (info and info.cc): raise IRCBridgeSignal('no-matching-chan')
					await self.discord.cmd_msg_send(info.cc, m.line)
				except IRCBridgeSignal as err:
					m.conn.cmd_msg_synth( self.nick_sys, m.chan,
						f'ERR {{{err}}}: {self._repr(m.line)}', notice=True, direct=True )
					while True: # flush queue to ensure ordering
						try: m = self.irc_msg_queue.get_nowait()
						except asyncio.QueueEmpty: break
						if m is StopIteration: break
						m.conn.cmd_msg_synth( self.nick_sys, m.chan,
							f'ERR-flush {{{err}}}: {self._repr(m.line)}', notice=True, direct=True )
					if m is StopIteration: break
		finally: self.irc_msg_queue = None


	def cmd_delay(self, delay, func=None):
		if func is None: delay, func = 0, delay
		if delay and not isinstance(delay, (int, float)):
			if delay == 'irc_auth': delay = next(self.irc_auth_tbf)
			else: raise ValueError(delay)
		if delay: self.tasks.add(asyncio.sleep(delay), func)
		else: self.tasks.add(aio_await_wrap(func))

	@iter_gather(irc_name_dict)
	def cmd_conn_map(self):
		for conn in self.irc_conns.values():
			if conn.st.nick: yield (conn.st.nick, conn)

	def cmd_conn(self, name=None):
		'Get irc connection for sending a direct message'
		try:
			if not name: return next(iter(self.irc_conns.values()))
			return self.cmd_conn_map()[name]
		except (KeyError, StopIteration): return

	@iter_gather(list)
	def cmd_chan_conns(self, name):
		'Get list of irc connections for users in a channel'
		for conn in self.irc_conns.values():
			chan_name = conn.chan_name(name)
			if ( chan_name in conn.st.chans
					or self.conf._irc_chan_auto_join_re.search(chan_name) ):
				yield conn

	@iter_gather(list)
	def cmd_chan_names_discord(self, name):
		'''List nicks from discord, in most recently
			active first order, doing auto-cleanup on these.'''
		info = self.irc_chan_info(name)
		if not (info and info.cc): return
		users, ts_cutoff = info.cc.get('users', dict()), time.time() - self.irc_names_timeout
		for u in sorted(users.values(), key=op.itemgetter('ts'), reverse=True):
			if u.ts < ts_cutoff: users.pop(u.name, None)
			else: yield u.name, self.irc_name(u.name)

	@iter_gather(list)
	def cmd_chan_names(self, name):
		'Returns persistent mutable list of users (/names) for specified channel.'
		conn_nicks = irc_name_dict.value_map(
			conn.st.nick for conn in self.cmd_chan_conns(name) if conn.st.nick )
		yield from sorted(conn_nicks.values())
		for nick_discord, nick_irc in self.cmd_chan_names_discord(name):
			if nick_irc not in conn_nicks: yield nick_irc

	@iter_gather(adict, cache=True)
	def cmd_chan_map(self, cache_track):
		'''Overloaded function to return cached adict of
				{chan-name: {name, topic, did, ts_created}},
			updating misc minor .cache.* maps used elsewhere in the process.'''
		cache_track(self.chans_sys)
		for name, topic in self.chans_sys.items():
			yield (name, adict(
				t=self.c_chan_type.sys, name=name,
				topic=topic, ts_created=self.server_ts.timestamp() ))
		cache_track(self.chans_mon)
		for name, topic in sorted(self.chans_mon.items(), key=op.itemgetter(0)):
			yield (name, adict(
				t=self.c_chan_type.mon, name=name,
				topic=topic, ts_created=self.server_ts.timestamp() ))
		cache_track(self.discord.st.guilds)
		for gg in sorted(
				self.discord.st.guilds.values(),
				key=op.itemgetter('ts_joined') ):
			cache_track(gg, 'name chans ts_joined')
			gid_pre = self.uid('guild', gg.id, kh=gg.get('kh'))
			self.cache.gid_prefix[gg.id] = gid_pre
			for cc in sorted(
					gg.chans.values(),
					key=lambda cc: (cc.get('pos') or 999, cc.name) ):
				cache_track(cc, 'name topic pos nsfw')
				name = f'{gid_pre}.{self.irc_name(cc.name)}'
				tags = '[NSFW] ' if cc.nsfw else ''
				topic = ' // '.join(filter(None, map(str.strip, (cc.topic or '').splitlines())))
				topic = f'{gg.name.strip()}: {tags}{topic}'.strip()
				self.cache.did_chan[cc.did] = name
				# Note: lowercase translation is handled by using different (proper) internal name
				yield (name.lower(), adict(
					t=self.c_chan_type.proxy, name=name,
					topic=topic, did=cc.did, ts_created=gg.ts_joined ))


	def cmd_chan_sys(self, name, conn, chan, line):
		if name not in self.c.chan_sys_list: return
		cmd_func = name[len(self.c.chan_prefix):]
		cmd_func = getattr(self, f'cmd_chan_sys_{cmd_func}', None)
		if cmd_func: cmd_func(conn, chan, line)

	def cmd_chan_sys_log_counts(self):
		counts = self.conf._debug_counts
		counts = (' '.join( '{}={:,d}'.format(k, counts[k]) for n, k in
			sorted(((n, k.lower()) for n, k in logging._levelToName.items()), reverse=True)
			if counts[k] > 0 ) + f' all={counts["all"]:,d}').strip()
		return counts

	def cmd_chan_sys_control_status(self, send):
		sess_state = self.discord.st.get('state', 'none')
		send('\n'.join([ 'Status:',
			f'  discord-state: {sess_state}',
			f'  log-msg-counts: {self.cmd_chan_sys_log_counts()}' ]))

	def cmd_chan_sys_control(self, conn, chan, line_raw):
		line = line_raw.strip().lower().split()
		if not line: return
		cmd, send = line[0],\
			ft.partial(conn.cmd_msg_synth, self.nick_sys, chan)
		if cmd in ['h', 'help']:
			self.cmd_chan_sys_control_status(send)
			send('\n'.join([
				'Commands:',
				'  status - (alias: st) show whether discord is connected and working',
				'  connect - (alias: on) connect/login to discord',
				'  disconnect - (alias: off) disconnect from discord',
				'  set [-s|--save] [option value] - set config option value,'
						' saving it to the last ini file if -s/--save is specified.'
					'\n    Run without args to get full list of options with their current values.',
				'Only immediate response to sent commands is logged here - no noise over time.' ]))
		elif cmd in ['status', 'st']: self.cmd_chan_sys_control_status(send)
		elif cmd in ['connect', 'on']:
			send('discord: connection started')
			self.discord.connect()
		elif cmd in ['disconnect', 'off']:
			send('discord: disconnecting')
			self.discord.disconnect()
		elif cmd == 'set':
			sec_re = re.compile('^({})_(.*)$'.format(
				'|'.join(map(re.escape, self.conf._conf_sections)) ))
			if len(line) == 1:
				send(f'Current config options/values:')
				val_types = [str, bool, int, float]
				for k in sorted(dir(self.conf)):
					if not sec_re.search(k): continue
					k_ini, v = k.replace('_', '-'), self.conf.get(k, raw=True)
					for vt in val_types:
						if isinstance(v, vt): break
					else: continue
					v = ['no', 'yes'][v] if vt is bool else repr(v)
					if vt is str and k == 'auth' or 'password' in k: v = '<hidden>'
					send(f'  {k_ini} = {v} [{vt.__name__}]')
				send( 'Note: string values must be quoted when setting'
					' them (using python str literal rules), e.g.: set irc-prefix-edit \'[ed] \'' )
				return send( 'Note: not all option changes take effect'
					' without reconnect or full restart, save them to config for latter' )
			conf_save = line[1] in ['-s', '--save']
			line = line_raw.lstrip().split(None, 2 + int(conf_save))[1 + int(conf_save):]
			if not 1 <= len(line) <= 2:
				return send('ERROR: "set" command needs "option [value]" arguments')
			v_conf = None
			try:
				k_ini, v_raw = line if len(line) != 1 else (line[0], '""')
				k, v = k_ini.replace('-', '_'), v_raw
				v_conf, sec = self.conf.get(k, raw=True), sec_re.search(k)
				if not sec: raise KeyError(k)
				vt, (sec, k_sec) = type(v_conf), sec.groups()
				if isinstance(v_conf, str):
					v = ast.literal_eval(v)
					if not isinstance(v, str): raise ValueError(v)
				v = self.conf.get_val_conv_func(v_conf)(v)
				if vt is not type(v): raise TypeError(v)
			except Exception as err:
				vt = f' ({vt.__name__})' if v_conf is not None else ''
				return send(f'ERROR: failed to parse {k_ini} = [{v_raw}]{vt} - {err_fmt(err)}')
			self.conf.set(k, v)
			if conf_save:
				save = self.conf.update_file_section(sec, k_sec)
				save = f' [saved to a file: {save}]'
			else: save = ''
			send(f'Updated conf value: {k_ini} = {v!r}{save}')

	def cmd_chan_sys_debug(self, conn, chan, line):
		line_src, line = line, line.strip().lower().split()
		pt_n, pt_cut = (self.conf.get(f'debug_chan_proto_{k}') for k in ['tail', 'cut'])
		if not line: return
		send = ft.partial(conn.cmd_msg_synth, self.nick_sys, chan)
		if line[0] in ['h', 'help', 'st', 'status']:
			level = proto_log_info = '???'
			proto_log_shared = ['no', 'yes'][bool(log_proto_root.propagate)]
			if self.conf._debug_chan:
				level = logging.getLevelName(self.conf._debug_chan.level).lower()
			if self.conf._debug_proto:
				proto_log_info = logging.getLevelName(self.conf._debug_proto.level).lower()
				proto_log_info = ( 'disabled' if proto_log_info == 'warning'
					else f'enabled, file={self.conf._debug_proto.get_file()}' )
			return send('\n'.join(f'-- {line}' for line in [
				'This channel is for logging output, with level=warning by default,',
				'  unless --debug is specified on command line, or [debug] verbose=yes in ini.',
				f'Status:',
				f'  log level: {level}',
				f'  log msg counts: {self.cmd_chan_sys_log_counts()}',
				f'  protocol log: {proto_log_info}',
				f'  protocol log shared: {proto_log_shared}',
				'Recognized commands here:',
				'  level warning - (alias: w) only dump warnings and errors here',
				'  level info - (alias: i) set level=info (default) logging in this channel',
				'    That mostly adds connection stuff - disconnects, reconnects, auth, etc.',
				'  level debug - (alias: d) enable level=debug logging in this channel',
				'    Includes protocol info (if shared), events, messages and everything else.',
				'  level error, level critical - more quiet than other levels above',
				'  proto {file} - enable irc/discord protocol logging to specified file',
				'  proto off - (alias: px) disable irc/discord protocol logging',
				'  proto share/unshare - (alias: ps/pu)',
				'    whether to dump protocol logging (level=debug) to regular logs',
				f'  proto tail [n] [cut] - (alias: pt) dump "n" (default={pt_n}) tail lines',
				f'    of protocol log file (if enabled), limited to "cut" length (default={pt_cut}).',
				'  cache stats - (alias: cs) print hit/miss info on some internal caches' ]))
		with cl.suppress(KeyError):
			line = dict(
				i='level info', d='level debug', w='level warning',
				cs='cache stats', px='proto off', ps='proto share',
				pu='proto unshare', pt='proto tail' )[line[0]].split() + line[1:]
		cmd, arg = line[0], line[1] if len(line) >= 2 else None
		if cmd == 'level' and len(line) == 2:
			level = getattr(logging, arg.upper(), None)
			if level is not None and self.conf._debug_chan:
				arg_old = logging.getLevelName(self.conf._debug_chan.level)
				self.conf._debug_chan.setLevel(level)
				send(f'-- logging level: {arg_old.lower()} -> {arg.lower()}')
			else: send(f'-- failed to change logging level: level or logger unavailable')
		elif cmd == 'proto':
			if arg == 'off':
				if self.conf._debug_proto:
					self.conf._debug_proto.setLevel(logging.WARNING)
				else: arg = 'unavailable'
				send(f'-- protocol log: {arg}')
			elif arg in ['share', 'unshare']:
				share = arg == 'share'
				send(f'-- protocol log shared: {str(share).lower()}')
				log_proto_root.propagate = share
			elif arg == 'tail':
				if not self.conf._debug_proto: send(f'-- protocol log disabled, nothing to show')
				else:
					if len(line) > 2: pt_n = int(line[2])
					if len(line) > 3: pt_cut = int(line[3])
					lines = file_tail(self.conf._debug_proto.get_file(), pt_n)
					send(f'-- protocol log tail [{len(lines)}/{pt_n}:{pt_cut}]:')
					for line in lines: send(f'--- {str_repr(line, max_len=pt_cut)}')
					send(f'-- protocol log tail end')
			elif len(line) >= 2:
				path = line_src.strip().split(None, 1)[-1] # preserve spaces and case
				if self.conf._debug_proto:
					self.conf._debug_proto.set_file(path)
					self.conf._debug_proto.setLevel(logging.DEBUG)
					arg = f'file={path}'
				else: arg = 'unavailable'
				send(f'-- protocol log: {arg}')
		elif cmd == 'cache':
			if arg == 'stats':
				send(f'-- cache stats:')
				stats = dict()
				for (k, t), n in iter_gather.cache_stats.items():
					stats.setdefault(k, [0, 0])[t != 'hit'] = n
				for k, (n_hit, n_miss) in stats.items():
					send(
						f'--- {k}: {n_hit:,d} / {n_hit + n_miss:,d}'
						f' [{100 * n_hit / (n_hit + n_miss):.1f}%]' )
				send(f'-- cache stats end')

	def cmd_log(self, line):
		if not self.init: return
		conn = self.cmd_conn()
		if not conn: return
		conn.cmd_msg_synth( self.nick_sys,
			conn.chan_spec(self.c.chan_debug), line )

	async def cmd_info(self, conn, t, id_str):
		t = {'#': 'channels', '@': 'users', '%': 'guilds'}[t]
		info_url = f'{t}/{id_str}'
		info = await self.discord.cmd_info_dump(info_url)
		conn.cmd_msg_self(self.nick_sys, f'--- [{info_url}] info follows')
		conn.cmd_msg_self(self.nick_sys, info)
		conn.cmd_msg_self(self.nick_sys, f'--- [{info_url}] end')

	def cmd_msg_monitor( self, msg,
			conn=None, nick=None, pre='', notice=True, gid=None ):
		if not conn: conn = self.cmd_conn()
		if not conn: return
		lines, n = list(filter(None, msg.splitlines())), self.conf.irc_len_monitor_lines
		if len(lines) > n:
			lines_n, lines = len(lines), lines[:n]
			lines[-1] += f' ... [{len(lines)}/{lines_n} lines]'
		c, n = conn.chan_spec(self.c.chan_monitor), self.conf.irc_len_monitor
		nick = nick or self.nick_sys
		if gid is not None: gid = self.cache.gid_prefix.get(gid)
		if gid:
			name = self.c.chan_monitor_guild_prefix + gid
			gid = conn.chan_spec(name)
			if name not in self.chans_mon: # kinda bad: never removed, invisible until activity
				self.chans_mon[name] = ( 'rdircd: read-only'
					' catch-all channel for messages from one discord' )
		for s in lines:
			s = f'{pre}{str_repr(s, n, len_bytes=True)}'
			conn.cmd_msg_synth(nick, c, s, notice=notice)
			if gid: conn.cmd_msg_synth(nick, gid, s, notice=notice)

	def cmd_msg_discord( self, cc, nick, line,
			tags=None, ts=None, conn=None, notice=None, skip_monitor=False ):
		# Must be synchronous wrt all discord data,
		#  as it can be called right before channel delete/rename.
		if ts: self.conf.state_set(self.uid_start, ts)
		prefix, name = '', self.cache.did_chan.get(cc.did)
		if nick:
			if nick not in cc.users: cc.users[nick] = adict(name=nick)
			cc.users[nick].ts = ts or time.time()
		direct = bool(conn)
		if direct: conn_list = [conn]
		else:
			conn_list = self.cmd_chan_conns(name) if name else list()
			conn = conn_list[0] if conn_list else self.cmd_conn()
		if not conn: return
		if tags:
			mt, prefix = DiscordSession.c_msg_tags, tags.pop('_prefix', prefix)
			for k, (tt, v) in tags.items():
				if tt == mt.user: v = '@' + self.irc_name(v)
				elif tt == mt.chan: v = conn.chan_spec(self.cache.did_chan.get(v, v))
				line = line.replace(k, v)
		if nick: nick = self.irc_name(nick)
		else:
			nick = self.nick_sys
			if notice is None: notice = True
		if not (direct or skip_monitor):
			self.cmd_msg_monitor( line, conn=conn, nick=nick,
				pre=f'#{name} :: {prefix}', notice=notice, gid=cc.gid )
		if not name:
			self.log.warning( 'Failed to resolve channel did'
				' {!r} [cc={}] for line: [{}] {}', cc.did, cc, nick, tags, nick, line )
		for conn in conn_list:
			conn.cmd_msg_synth( nick,
				conn.chan_spec(name), f'{prefix}{line}', notice=notice, direct=True )



class RDIRCDConfig(RDIRCDConfigBase):

	ws_dump_filter = None
	ws_dump_file = 'dump.json'
	# ws_dump_filter = adict(op=0, t='READY')

	state_tracked, state, aliases = True, None, None
	_state_section = _state_offsets = _state_file = _state_file_ts = None
	_debug_chan = _debug_proto = _debug_counts = None

	def __init__(self):
		self.state, self.aliases = dict(), dict()
		self.log = get_logger('rdircd.state')
		for k in dir(self):
			if k.startswith('_conv_'): k = k[6:]
			else: continue
			self.set(k, self.get(k))

	def __repr__(self): return repr(vars(self))
	def get(self, *k, raw=False):
		k = '_'.join(k).replace('-', '_')
		if not raw:
			with cl.suppress(AttributeError): return getattr(self, f'_{k}')
		return getattr(self, k)
	def set(self, k, v):
		k = k.replace('-', '_')
		k_conv, v_conv = f'_{k}', getattr(self, f'_conv_{k}', None)
		if v_conv: setattr(self, k_conv, v_conv(v))
		setattr(self, k, v)

	def read(self, func, section, k, conf_k=None, section_old=None):
		if not conf_k: conf_k = f'{section}_{k}'.replace('-', '_')
		for k in set([k, k.replace('-', '_'), k.replace('_', '-')]):
			try:
				self.set(conf_k, func(section_old or section, k))
				return True
			except configparser.NoSectionError: pass
			except configparser.NoOptionError: pass

	def pprint(self, title=None, empty_vals=False, comments=None):
		cat, comms, chk = None, comments or dict(), re.compile(
			'^({})_(.*)$'.format('|'.join(map(re.escape, self._conf_sections))) )
		if title: print(f';; {title}')
		if '_notes' in comms: print(comms['_notes'])
		for k in sorted(dir(self)):
			m = chk.search(k)
			if not m: continue
			v = self.get(k, raw=True)
			if not empty_vals and not v: continue
			cat_chk = m.group(1).replace('_', '-')
			if cat_chk != cat:
				cat = cat_chk
				print(f'\n[{cat}]')
			if isinstance(v, bool): v = ['no', 'yes'][v]
			k = m.group(2).replace('_', '-')
			k_full = f'{cat}-{k}'
			if k_full in comms:
				comm = comms[k_full]
				if comm.startswith(f'; {k_full}'): comm = f'; {k}' + comm[len(k_full) + 2:]
				print(comm)
			print(f'{k} = {v}')
		if self.aliases:
			print('\n[aliases]')
			for k, v in self.aliases.items(): print(f'{".".join(k)} = {v}')

	def read_from_file(self, *conf_paths):
		conf_file = configparser.ConfigParser(allow_no_value=True)
		conf_file.optionxform = lambda k: k
		conf_file.read(conf_paths)
		self._conf_path = conf_paths[-1]
		for k, k_new in list(self._conf_sections_old.items()):
			if not self.update_from_file_section(
					conf_file, section=k_new, prefix=f'{k_new}_', section_old=k ):
				# Warnings will be issued for existing keys after logging is configured later
				del self._conf_sections_old[k]
		for k in self._conf_sections:
			self.update_from_file_section(conf_file, section=k, prefix=f'{k}_')
		self.read(conf_file.getboolean, 'state', 'tracked')
		self._state_section = conf_file.has_section('state')
		if self.state_tracked and self._state_section:
			for k, v in conf_file['state'].items():
				if k == 'tracked': continue
				self.state[k] = parse_iso8601(v)
		if conf_file.has_section('aliases'):
			for k, v in conf_file['aliases'].items():
				if '.' not in k: continue
				self.aliases[tuple(k.lower().split('.', 1))] = v

	def get_val_conv_func(self, v, conf_get=lambda *a,**k: a[0]):
		if v is str or isinstance(v, str): return lambda *a: str(conf_get(*a, raw=True))
		elif v is bool or isinstance(v, bool):
			bool_map = {
				'1': True, 'yes': True, 'y': True, 'true': True, 'on': True,
				'0': False, 'no': False, 'n': False, 'false': False, 'off': False }
			def bool_get(*a):
				v = conf_get(*a)
				try: return bool_map[str(v).strip().lower()]
				except KeyError: raise ValueError(v)
			return bool_get
		elif v is int or isinstance(v, int): return lambda *a: int(re.sub(r'[ _]', '', conf_get(*a)))
		elif v is float or isinstance(v, float): return lambda *a: float(conf_get(*a))

	def update_from_file_section(self,
			config, section='default', prefix=None, section_old=None ):
		if section_old: section_old = section_old.replace('_', '-')
		section_old_warn, section = None, section.replace('_', '-')
		for k in dir(self):
			if prefix:
				if not k.startswith(prefix): continue
				conf_k, k = k, k[len(prefix):]
			elif k.startswith('_'): continue
			else: conf_k = k
			v = getattr(self, conf_k)
			get_val = self.get_val_conv_func(v, config.get)
			if not get_val: continue # other types cannot be specified in config
			if self.read( get_val, section, k, conf_k,
				section_old=section_old ) and section_old: section_old_warn = True
		return section_old_warn


	def update_file_section(self, section, keys=None, path=None):
		section = section.replace('_', '-')
		if not path: path = self._conf_path
		if isinstance(path, str): path = pl.Path(path)
		sec_re, sec_k = re.compile(r'(?i)^\[\s*(\S+)\s*\]$'), str_norm(section)
		sec_prefix = section.lower().replace('-', '_') + '_'
		if not keys: keys = list(k for k in vars(self).keys() if k.startswith(sec_prefix))
		if isinstance(keys, str): keys = keys.split()
		if isinstance(keys, dict): keys = list(keys.items())
		for n, k in enumerate(keys):
			if isinstance(k, tuple): k, v = k
			else: v = ...
			k = k.replace('_', '-')
			if not k.startswith(sec_prefix): k = sec_prefix + k
			if v is ...: v = self.get(k, raw=True)
			k = k[len(sec_prefix):]
			if isinstance(v, bool): v = ['no', 'yes'][v]
			keys[n] = k, v, re.compile(r'(?i)^' + k.replace('-', '[-_]') + r'\s*=')
		keys = dict((k, (v, rx)) for k, v, rx in keys)
		with path.open() as src, safe_replacement(path) as dst:
			lines, sec, sec_parse = list(), list(), False
			for n, line in enumerate(src):
				m, line = sec_re.search(line.strip()), line.rstrip()
				if m:
					k = str_norm(m.group(1))
					if k == sec_k:
						sec_parse = True
						if sec: line = '' # drop duplicate headers
					if k != sec_k: sec_parse = False
				if sec_parse: sec.append(line)
				else: lines.append(line)
			while sec and not sec[-1]: sec.pop()
			if not sec: sec.append(f'[{section}]')
			if lines and lines[-1]: lines.append('')
			for line in lines: dst.write(f'{line}\n')
			for n, line in enumerate(sec):
				for k, (v, rx) in keys.items():
					if not rx.search(line): continue
					if v is None: line = None
					else: line, keys[k] = f'{k} = {v}', (None, rx)
				if line is not None: dst.write(f'{line}\n')
			for k, (v, rx) in keys.items():
				if v is None: continue
				dst.write(f'{k} = {v}\n')
		self._state_source_flush()
		return path

	### Timestamps in [state] section are updated in-place,
	###  overwriting short timestamp values without tmp files.
	### File should be safe to edit manually regardless, due to ctime checks.

	def _state_source_flush(self):
		self._state_file = self._state_offsets = None

	def _state_source_get(self):
		if self._state_file and self._state_file_ts:
			try: ts = os.stat(self._state_file.name).st_ctime
			except OSError: ts = None
			if ts != self._state_file_ts: self._state_source_flush()
		if not self._state_file: self._state_file = open(self._conf_path, 'rb+')
		if self._state_offsets is None: self._state_offsets = self._state_offsets_read()
		return self._state_file, self._state_offsets

	def _state_offsets_read(self, section='state'):
		section, src = section.replace('_', '-'), self._state_file
		sec_re, sec_k = re.compile(r'(?i)^\[\s*(\S+)\s*\]$'), str_norm(section)
		src.seek(0)
		offsets, parse = dict(), False
		val_re = re.compile(b'^\s*([\w\d]\S+)\s*=\s*(\S+)\s*$')
		for line in iter(src.readline, b''):
			m = sec_re.search(line.decode().strip())
			if m:
				k = str_norm(m.group(1))
				if k == sec_k: parse = True
				else: parse = False
				continue
			if parse:
				m = val_re.search(line)
				if not m: continue
				k, v = m.group(1), m.group(2)
				pos = src.tell() - len(line) + m.start(2)
				offsets[k.decode()] = pos
				# src.seek(pos)
				# v_chk = src.read(len(v))
				# assert v_chk == v, [pos, v_chk, v]
				# src.readline()
		return offsets

	def state_get(self, k, t='last-msg'): return self.state.get(f'{t}.{k}')

	def state_set(self, k, ts, t='last-msg', sync=False):
		if not self.state_tracked: return
		if not self._state_section: self.update_file_section('state', 'tracked')
		k, v = f'{t}.{k}', ts_iso8601(ts)
		if k not in self.state:
			self.update_file_section('state', {k: v})
			self.state[k] = ts
			return self.state_cleanup()
		if self.state[k] > ts: return
		src, offsets = self._state_source_get()
		n, v = offsets[k], v.encode()
		src.seek(n)
		parse_iso8601(src.read(len(v)).decode(), validate=True)
		src.seek(n)
		src.write(v)
		src.flush()
		if sync: os.fdatasync(src.fileno())
		self.state[k], self._state_file_ts = ts, os.fstat(src.fileno()).st_ctime

	def state_cleanup(self, keep_max=10):
		keys = sorted((v,k) for k,v in self.state.items())
		if len(keys) <= keep_max: return
		src, offsets = self._state_source_get()
		offsets = sorted( ((offsets[k], k) for v,k in
			keys[:len(keys) - keep_max]), reverse=True )
		with src, safe_replacement(src.name, 'wb') as dst:
			src.seek(0)
			for line in iter(src.readline, b''):
				if offsets and offsets[-1][0] < src.tell():
					n, k = offsets.pop()
					del self.state[k]
					continue
				dst.write(line)
		self._state_source_flush()



def parse_conf_code_comments():
	'Parses "class RDIRCDConfigBase" in __file__, returns {var: comment} dict'
	def line_proc(line):
		var = line.split(None, 1)[0] if re.search(r'^\S+\s+=', line) else ''
		var, var_code = var.replace('_', '-'), var
		try: pre, comm = line.split('#', 1)
		except ValueError: comm = ''
		if comm.lstrip().startswith('XXX:'): comm = ''
		if comm.startswith(' '): comm = comm[1:]
		return var, var_code, comm
	comms = dict()
	if __file__.endswith('.pyc'): return
	try: src_file = open(__file__, errors='replace')
	except OSError: return
	with src_file as src:
		if src.read(3) != '#!/': return
		for line in src:
			if line.startswith('class RDIRCDConfigBase'): break
		comm_buffer = list()
		for line in src:
			ls = line.strip()
			if ls and not line.startswith('\t'): break
			var, var_code, comm = line_proc(ls)
			if var_code.startswith('_'): break
			if not var:
				if comm: comm_buffer.append(comm)
			else:
				if comm_buffer: comm = ((comm or '') + '\n' + '\n'.join(comm_buffer)).strip()
				if comm:
					if var and re.search('^' + re.escape(var_code) + r'\s+', comm):
						comm = var + comm[len(var_code):]
					if not comm.startswith(var): comm = f'{var}: {comm}'
					comms[var] = comm
			if comm_buffer and (not comm or var):
				if not comms: comms['_notes'] = '\n'.join(comm_buffer)
				comm_buffer.clear()
	for k, comm in comms.items(): comms[k] = '\n'.join(f'; {line}' for line in comm.split('\n'))
	return comms

def main(args=None, conf=None):
	if not conf: conf = RDIRCDConfig()

	import argparse, textwrap
	dedent = lambda text: (textwrap.dedent(text).strip('\n') + '\n').replace('\t', '  ')
	text_fill = lambda s,w=100,ind='\t',ind_next=None,**k: textwrap.fill(
		s, w, initial_indent=ind, subsequent_indent=ind if ind_next is None else ind_next, **k )
	class SmartHelpFormatter(argparse.HelpFormatter):
		def __init__(self, *args, **kws):
			return super().__init__(*args, **kws, width=100)
		def _fill_text(self, text, width, indent):
			if '\n' not in text: return super()._fill_text(text, width, indent)
			return ''.join( indent + line
				for line in text.replace('\t', '  ').splitlines(keepends=True) )
		def _split_lines(self, text, width):
			return super()._split_lines(text, width)\
				if '\n' not in text else dedent(text).splitlines()

	parser = argparse.ArgumentParser(
		formatter_class=SmartHelpFormatter,
		description='Reliable personal discord-client to irc-server translation daemon.')

	group = parser.add_argument_group('Configuration file(s)')
	group.add_argument('-c', '--conf',
		metavar='file', action='append',
		help=f'''
			Path to configuration file to use.
			It will get updated with OAuth2 credentials ([auth] section)
				and some state info ([state] section), so has to be writable.
			Can be specified mutliple times to use multiple config files,
				in which case only last one will be updated and has to be writable.
			Default: {conf._conf_path}''')
	group.add_argument('--conf-dump', action='store_true',
		help='Print all configuration settings, which will be used with'
			' currently detected (and/or specified) configuration file(s), and exit.')
	group.add_argument('--conf-dump-defaults', action='store_true',
		help='Print all default settings which would be used if no'
			' configuration file(s) were overriding these, with some comments, and exit.')
	group.add_argument('--conf-dump-state', action='store_true',
		help='Print "state" section from the config file,'
			' with keys corresponding to app startups and iso8601'
			' time values of last received message for that run.')

	group = parser.add_argument_group('Interfaces')
	group.add_argument('-i', '--irc-bind', metavar='host(:port)',
		help=f'''
			Address/host (to be resolved via gai) and port to bind IRC server to.
			When specifying port after raw IPv6 address,
				enclose the latter in [], for example - [::]:6667.
			Default: {conf.irc_host}:{conf.irc_port} or whatever is in --conf file.''')

	group = parser.add_argument_group('Logging and debug opts')
	group.add_argument('-d', '--debug',
		action='store_true', help='Verbose operation mode.')
	group.add_argument('--debug-asyncio',
		action='store_true', help='Run asyncio event loop in debug mode. Very verbose.')
	group.add_argument('-t', '--proto-cut', type=int, metavar='n',
		help='Truncate long strings in protocol dumps to specified length.'
			' Set to <=0 to disable truncation (default).')
	group.add_argument('-p', '--proto-log', metavar='file',
		help='''
			File to dump full non-truncated protocol logs to.
			Max file size and rotation options can be configured via --conf file.''')
	group.add_argument('-l', '--debug-log', metavar='file',
		help='''
			Separate file for debug-level logging, regardless of levels set elsewhere.
			Max file size and rotation options can be configured via --conf file.''')

	opts = parser.parse_args(sys.argv[1:] if args is None else args)

	if opts.conf_dump_defaults:
		conf.pprint( 'Default configuration options',
			empty_vals=True, comments=parse_conf_code_comments() )
		return

	conf_user_paths = list(map(
		os.path.expanduser, opts.conf or [conf._conf_path] ))
	for n, p in enumerate(conf_user_paths):
		mode = os.R_OK
		if n == len(conf_user_paths) - 1: mode |= os.W_OK
		if not os.access(p, mode):
			parser.error(f'Specified config file missing or inaccessible: {p}')
	conf.read_from_file(*conf_user_paths)

	if opts.conf_dump:
		conf.pprint('Current configuration options')
		return
	if opts.conf_dump_state:
		print('state_timestamps:')
		for v, k in sorted((v,k) for k,v in conf.state.items()):
			print(f'  {k}: {ts_iso8601(v)}')
		return

	if opts.debug: conf.debug_verbose = True
	if opts.debug_asyncio: conf.debug_asyncio = True
	if opts.debug_log: conf.debug_log_file = opts.debug_log
	if opts.proto_cut: conf.debug_proto_cut = opts.proto_cut
	if opts.proto_log: conf.debug_proto_log_file = opts.proto_log

	log_fmt = '{name} {levelname:5} :: {message}'
	if conf.debug_verbose: log_fmt = '{asctime} :: ' + log_fmt
	log_fmt = logging.Formatter(log_fmt, style='{')
	log_handler = logging.StreamHandler(sys.stderr)
	log_handler.setLevel( logging.DEBUG
		if conf.debug_verbose else logging.WARNING )
	log_handler.setFormatter(log_fmt)
	log_handler.addFilter(log_empty_filter)
	logging.root.addHandler(log_handler)
	logging.root.setLevel(0)
	log = get_logger('main')

	log_handler = LogLevelCounter()
	logging.root.addHandler(log_handler)
	conf._debug_counts = log_handler.counts

	if conf.debug_log_file:
		log_handler = LogFileHandler(
			conf.debug_log_file,
			maxBytes=conf.debug_log_file_size,
			backupCount=conf.debug_log_file_count )
		log_handler.setLevel(logging.DEBUG)
		log_handler.setFormatter(logging.Formatter(
			'{asctime}.{msecs:03.0f} :: {name} {levelname:5} :: {message}',
			datefmt='%Y-%m-%dT%H:%M:%S', style='{' ))
		logging.root.addHandler(log_handler)

	log_proto_root.propagate = conf.debug_proto_log_shared
	log_handler = conf._debug_proto = LogFileHandler(
		conf.debug_proto_log_file or '/dev/null',
		maxBytes=conf.debug_proto_log_file_size,
		backupCount=conf.debug_proto_log_file_count )
	log_handler.setLevel( logging.DEBUG
		if conf.debug_proto_log_file else logging.WARNING )
	log_handler.setFormatter(LogProtoFormatter(
		'%(asctime)s :: %(reltime)s :: %(name)s :: %(message)s' ))
	log_handler.addFilter(log_proto_debug_filter)
	log_proto_root.addHandler(log_handler)

	def handle_exception(err_t, err, err_tb):
		log.error('Unhandled error: {}', err_fmt(err), exc_info=(err_t, err, err_tb))
	sys.excepthook = handle_exception

	for k_old, k_new in conf._conf_sections_old.items():
		k_old, k_new = (k.replace('_', '-') for k in [k_old, k_new])
		log.warning( 'Old and deprecated section'
			' in config file(s) - {!r} - replace it with {!r}', k_old, k_new )

	host, port, family = opts.irc_bind or conf.irc_host, conf.irc_port, conf.irc_host_af
	if host.count(':') > 1: host, port = str_part(host, ']:>', port)
	else: host, port = str_part(host, ':>', port)
	if '[' in host: family = socket.AF_INET6
	host, port = host.strip('[]'), int(port)
	try:
		addrinfo = socket.getaddrinfo( host, str(port),
			family=family, type=socket.SOCK_STREAM, proto=socket.IPPROTO_TCP )
		if not addrinfo: raise socket.gaierror(f'No addrinfo for host: {host}')
	except (socket.gaierror, socket.error) as err:
		parser.error( 'Failed to resolve irc socket parameters (address, family)'
			' via getaddrinfo: {!r} - [{}] {}'.format((host, port), err.__class__.__name__, err) )
	sock_af, sock_t, sock_p, _, sock_addr = addrinfo[0]
	log.debug(
		'Resolved irc host:port {!r}:{!r} to endpoint: {} (family: {}, type: {}, proto: {})',
		host, port, sock_addr, *(sockopt_resolve(pre, n)
			for pre, n in [('af_', sock_af), ('sock_', sock_t), ('ipproto_', sock_p)]) )
	assert ( sock_t == socket.SOCK_STREAM
		and sock_p == socket.IPPROTO_TCP ), [sock_t, sock_p]
	conf.irc_host_af, (conf.irc_host, conf.irc_port) = sock_af, sock_addr[:2]

	async def run_rdircd():
		loop, rdircd = asyncio.get_running_loop(), RDIRCD(conf)

		log_handler = conf._debug_chan = LogFuncHandler(rdircd.cmd_log)
		log_handler.setLevel(logging.DEBUG if conf.debug_verbose else logging.WARNING)
		log_handler.setFormatter(logging.Formatter(
			'{name} {levelname:5} :: {message}', style='{' ))
		log_handler.addFilter(log_empty_filter)
		log_handler.addFilter(log_proto_debug_filter)
		logging.root.addHandler(log_handler)

		rdircd_task = asyncio.create_task(rdircd.run_async())
		for sig in 'INT TERM'.split():
			loop.add_signal_handler(getattr(signal, f'SIG{sig}'), rdircd_task.cancel)
		with cl.suppress(asyncio.CancelledError): return await rdircd_task

	log.debug('Starting eventloop...')
	return asyncio.run(run_rdircd(), debug=conf.debug_asyncio)
	log.debug('Finished')

if __name__ == '__main__': sys.exit(main())
